[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/perceptron_blog.html",
    "href": "posts/perceptron_blog.html",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "In this blog post, I examine a way to find a line that separates two sets of data using the perceptron algorithm. I will see how this perceptron algorithm works well in two dimensions but also on n-dimensional data. I will also examine the limitations of this algorithm on non-linear seperable data. Lastly, I’ll examine a variant of the perceptron algorithm called the mini-batch perceptron algorithm.\n\n\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\n\nhttps://github.com/Hokalaka2/Hokalaka2.github.io/blob/main/posts/perceptron.py\n\n\n\nThis is where I implemented how I get perceptron data. This code was partially taken from our lectures and warm up. It basically adds randomness to the points and makes the points linear seperable. It also makes the targets -1 and 1 instead of 0, and 1 because it makes it easier to change the color of the points. We also add a method that allows us to plot our 2 dimensional points.\nLastly we plot the points to show what the points distribution looks like.\n\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ntorch.manual_seed(123456)\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n    y = y.type(torch.FloatTensor)\n\n    return X, y\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = perceptron_data()\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\n\n\n\nI select fifty of these points in order to use for my model because it felt somewhat uneccesarry to use all the points for this simple example. As we can see, the points are clearly linearly seperable.\n\ntorch.manual_seed(123456)\nX, y = perceptron_data(n_points = 50, noise = 0.3)\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 2), ylim = (-1, 2))\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\n\n\n\nI make a draw line function that allows us to vizualize the linear line that the model sets. This allows us to see progression and makes the Perceptron more intuitive.\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\ndef rgb_to_hex(rgb):\n    return '#{:02x}{:02x}{:02x}'.format(*rgb)\n\n\n\n\n\nfrom matplotlib.lines import Line2D\ndef perceptron_loop(X, y, max_iter = 1000, k = 1, alpha = 1.0, plot = False, plot_type = \"color\"):\n    p = Perceptron() \n    opt = PerceptronOptimizer(p, alpha)\n    \n    p.loss(X, y)\n\n    loss = 1.0\n    \n    if plot and plot_type == \"color\":\n        fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n        rgb = (255, 0, 0)\n        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n    if plot and plot_type == \"adjacent\":\n        plt.rcParams[\"figure.figsize\"] = (7, 5)\n        fig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\n        markers = [\"o\", \",\"]\n        marker_map = {-1 : 0, 1 : 1}\n        current_ax = 0\n\n    # for keeping track of loss values\n    loss_vec = []\n\n    lines = []\n    iter = 0\n    loss_w = []\n    while loss &gt; 0 and iter &lt; max_iter:\n        old_w = torch.clone(p.w)\n        i = torch.randperm(X.size(0))[:k]\n        x_i = X[i,:]\n        y_i = y[i]\n        local_loss = opt.step(x_i, y_i, k) \n        if local_loss &gt; 0:\n            loss = p.loss(X, y) \n            loss_vec.append(loss)\n            loss_w.append(torch.clone(p.w))\n            if plot and plot_type == \"adjacent\" and current_ax &lt; 6:\n                ax = axarr.ravel()[current_ax]\n                plot_perceptron_data(X, y, ax)\n                draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n                draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n                ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[y[i].item()]])\n                ax.set_title(f\"loss = {loss:.3f}\")\n                ax.set(xlim = (-1, 2), ylim = (-1, 2))\n                current_ax += 1\n        iter += 1\n    if plot and plot_type == \"color\":\n        plot_perceptron_data(X, y, ax)\n        for i in range(len(loss_vec)):\n            draw_line(loss_w[i], x_min = -1, x_max = 2, ax = ax, color = rgb_to_hex(rgb), linestyle = \"solid\")\n            lines.append(Line2D([0], [0], color=rgb_to_hex(rgb), lw=2, label=\"Line \" + str(len(lines) + 1), linestyle='-'))\n            red, green, blue = rgb\n            rgb = (red-int(280/len(loss_vec)), 0, 0)\n        ax.legend(handles = lines, loc=\"upper right\")\n    return loss_vec\n\n\n\n\nI wanted to make my own unique way to visualize the perceptron process so I made this fun color graph. The lines get darker as the model gets closer to convering. While it arguably works less successfully than the adjacent graph, it offers a new way to examine the process.\n\ntorch.manual_seed(123456)\nloss_vec = perceptron_loop(X, y, plot = True, plot_type = \"color\")\n\n\n\n\n\n\n\n\nHere is the algorithm loop but with adjacent graphs instead of different colored lines. This is more similar to what Prof. Phil did in class.\n\ntorch.manual_seed(123456)\nloss_vec = perceptron_loop(X, y, k = 1, plot = False, plot_type = \"adjacent\")\n\n\n\n\nHere we can see the model converge to zero loss. In order to clear up the graph, this graph only shows the changes in p.w’s and not every attempt.\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\n\n\n\n\n\n\n\n\n\n\nWhat if our data is not linearly seperable. In this next part, I make a completely random dataset. As we’ll see, it would be impossible to drawn a line in order to make a loss of 0.\n\ntorch.manual_seed(123456)\n\ndef random_data(n_points = 300, noise = 0.2, p_dims = 2):\n    X = torch.normal(0.0, noise, size = (n_points, p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    y = torch.rand(X.shape[0])\n    y = 1 * (y &gt; 0.5)\n    y = 2 * y - 1\n    y = y.type(torch.FloatTensor)\n    return X, y\n\ndef plot_random_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nX_rand, y_rand = random_data()\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 1), ylim = (-1, 1))\nplot_random_data(X_rand, y_rand, ax)\n\n\n\n\n\n\n\n\nSo how does our perceptron algorithm fair in this instance. We’ll as we can see in this next part, perceptron still tries to find a solution. It will jump around, trying new values but will never find a line that fits. This will continue forever. However, in my case, I have set a max number of iterations at 1000 so that it will stop then.\n\ntorch.manual_seed(123456)\n\nloss_vec = perceptron_loop(X_rand, y_rand, plot = True, plot_type = \"adjacent\")\n\n\n\n\n\n\n\n\nAs we can see, it continues to jump around but without any solution. In this example, our perceptron tries a little over 500 different lines.\n\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\n\n\n\n\n\n\n\n\n\n\nVery often data is not just 2 dimension. How does Perceptron work on 3, 4, 5 dimensional data sets. Well luckily, we can try this out! Our data method from the beginning allows us to change the number of dimensions of the dataset.\n\ntorch.manual_seed(123456)\n\nX_multiple, y_multiple = perceptron_data(n_points = 300, noise = 0.2, p_dims = 5)\n\n\n\n\nAs we can in the next graph, our algorithm still gets to zero loss! As long as our data is linearly seperable than perceptron algorithm will work.\n\nloss_vec = perceptron_loop(X_multiple, y_multiple, plot = False)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")"
  },
  {
    "objectID": "posts/perceptron_blog.html#loading-in-perceptron-implementation",
    "href": "posts/perceptron_blog.html#loading-in-perceptron-implementation",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "posts/perceptron_blog.html#perceptron-link",
    "href": "posts/perceptron_blog.html#perceptron-link",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "https://github.com/Hokalaka2/Hokalaka2.github.io/blob/main/posts/perceptron.py"
  },
  {
    "objectID": "posts/perceptron_blog.html#perceptron-data",
    "href": "posts/perceptron_blog.html#perceptron-data",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "This is where I implemented how I get perceptron data. This code was partially taken from our lectures and warm up. It basically adds randomness to the points and makes the points linear seperable. It also makes the targets -1 and 1 instead of 0, and 1 because it makes it easier to change the color of the points. We also add a method that allows us to plot our 2 dimensional points.\nLastly we plot the points to show what the points distribution looks like.\n\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ntorch.manual_seed(123456)\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n    y = y.type(torch.FloatTensor)\n\n    return X, y\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = perceptron_data()\nplot_perceptron_data(X, y, ax)"
  },
  {
    "objectID": "posts/perceptron_blog.html#examining-the-data",
    "href": "posts/perceptron_blog.html#examining-the-data",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "I select fifty of these points in order to use for my model because it felt somewhat uneccesarry to use all the points for this simple example. As we can see, the points are clearly linearly seperable.\n\ntorch.manual_seed(123456)\nX, y = perceptron_data(n_points = 50, noise = 0.3)\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 2), ylim = (-1, 2))\nplot_perceptron_data(X, y, ax)"
  },
  {
    "objectID": "posts/perceptron_blog.html#draw-line-function",
    "href": "posts/perceptron_blog.html#draw-line-function",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "I make a draw line function that allows us to vizualize the linear line that the model sets. This allows us to see progression and makes the Perceptron more intuitive.\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\ndef rgb_to_hex(rgb):\n    return '#{:02x}{:02x}{:02x}'.format(*rgb)"
  },
  {
    "objectID": "posts/perceptron_blog.html#perceptron-loop",
    "href": "posts/perceptron_blog.html#perceptron-loop",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "from matplotlib.lines import Line2D\ndef perceptron_loop(X, y, max_iter = 1000, k = 1, alpha = 1.0, plot = False, plot_type = \"color\"):\n    p = Perceptron() \n    opt = PerceptronOptimizer(p, alpha)\n    \n    p.loss(X, y)\n\n    loss = 1.0\n    \n    if plot and plot_type == \"color\":\n        fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n        rgb = (255, 0, 0)\n        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n    if plot and plot_type == \"adjacent\":\n        plt.rcParams[\"figure.figsize\"] = (7, 5)\n        fig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\n        markers = [\"o\", \",\"]\n        marker_map = {-1 : 0, 1 : 1}\n        current_ax = 0\n\n    # for keeping track of loss values\n    loss_vec = []\n\n    lines = []\n    iter = 0\n    loss_w = []\n    while loss &gt; 0 and iter &lt; max_iter:\n        old_w = torch.clone(p.w)\n        i = torch.randperm(X.size(0))[:k]\n        x_i = X[i,:]\n        y_i = y[i]\n        local_loss = opt.step(x_i, y_i, k) \n        if local_loss &gt; 0:\n            loss = p.loss(X, y) \n            loss_vec.append(loss)\n            loss_w.append(torch.clone(p.w))\n            if plot and plot_type == \"adjacent\" and current_ax &lt; 6:\n                ax = axarr.ravel()[current_ax]\n                plot_perceptron_data(X, y, ax)\n                draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n                draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n                ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[y[i].item()]])\n                ax.set_title(f\"loss = {loss:.3f}\")\n                ax.set(xlim = (-1, 2), ylim = (-1, 2))\n                current_ax += 1\n        iter += 1\n    if plot and plot_type == \"color\":\n        plot_perceptron_data(X, y, ax)\n        for i in range(len(loss_vec)):\n            draw_line(loss_w[i], x_min = -1, x_max = 2, ax = ax, color = rgb_to_hex(rgb), linestyle = \"solid\")\n            lines.append(Line2D([0], [0], color=rgb_to_hex(rgb), lw=2, label=\"Line \" + str(len(lines) + 1), linestyle='-'))\n            red, green, blue = rgb\n            rgb = (red-int(280/len(loss_vec)), 0, 0)\n        ax.legend(handles = lines, loc=\"upper right\")\n    return loss_vec"
  },
  {
    "objectID": "posts/perceptron_blog.html#color-representation",
    "href": "posts/perceptron_blog.html#color-representation",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "I wanted to make my own unique way to visualize the perceptron process so I made this fun color graph. The lines get darker as the model gets closer to convering. While it arguably works less successfully than the adjacent graph, it offers a new way to examine the process.\n\ntorch.manual_seed(123456)\nloss_vec = perceptron_loop(X, y, plot = True, plot_type = \"color\")\n\n\n\n\n\n\n\n\nHere is the algorithm loop but with adjacent graphs instead of different colored lines. This is more similar to what Prof. Phil did in class.\n\ntorch.manual_seed(123456)\nloss_vec = perceptron_loop(X, y, k = 1, plot = False, plot_type = \"adjacent\")"
  },
  {
    "objectID": "posts/perceptron_blog.html#convergence",
    "href": "posts/perceptron_blog.html#convergence",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "Here we can see the model converge to zero loss. In order to clear up the graph, this graph only shows the changes in p.w’s and not every attempt.\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")"
  },
  {
    "objectID": "posts/perceptron_blog.html#not-linearly-seperable-data",
    "href": "posts/perceptron_blog.html#not-linearly-seperable-data",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "What if our data is not linearly seperable. In this next part, I make a completely random dataset. As we’ll see, it would be impossible to drawn a line in order to make a loss of 0.\n\ntorch.manual_seed(123456)\n\ndef random_data(n_points = 300, noise = 0.2, p_dims = 2):\n    X = torch.normal(0.0, noise, size = (n_points, p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    y = torch.rand(X.shape[0])\n    y = 1 * (y &gt; 0.5)\n    y = 2 * y - 1\n    y = y.type(torch.FloatTensor)\n    return X, y\n\ndef plot_random_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nX_rand, y_rand = random_data()\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 1), ylim = (-1, 1))\nplot_random_data(X_rand, y_rand, ax)\n\n\n\n\n\n\n\n\nSo how does our perceptron algorithm fair in this instance. We’ll as we can see in this next part, perceptron still tries to find a solution. It will jump around, trying new values but will never find a line that fits. This will continue forever. However, in my case, I have set a max number of iterations at 1000 so that it will stop then.\n\ntorch.manual_seed(123456)\n\nloss_vec = perceptron_loop(X_rand, y_rand, plot = True, plot_type = \"adjacent\")\n\n\n\n\n\n\n\n\nAs we can see, it continues to jump around but without any solution. In this example, our perceptron tries a little over 500 different lines.\n\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")"
  },
  {
    "objectID": "posts/perceptron_blog.html#multiple-dimensions",
    "href": "posts/perceptron_blog.html#multiple-dimensions",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "Very often data is not just 2 dimension. How does Perceptron work on 3, 4, 5 dimensional data sets. Well luckily, we can try this out! Our data method from the beginning allows us to change the number of dimensions of the dataset.\n\ntorch.manual_seed(123456)\n\nX_multiple, y_multiple = perceptron_data(n_points = 300, noise = 0.2, p_dims = 5)"
  },
  {
    "objectID": "posts/perceptron_blog.html#result",
    "href": "posts/perceptron_blog.html#result",
    "title": "Perceptron Blog Post",
    "section": "",
    "text": "As we can in the next graph, our algorithm still gets to zero loss! As long as our data is linearly seperable than perceptron algorithm will work.\n\nloss_vec = perceptron_loop(X_multiple, y_multiple, plot = False)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")"
  },
  {
    "objectID": "posts/perceptron_blog.html#k-10",
    "href": "posts/perceptron_blog.html#k-10",
    "title": "Perceptron Blog Post",
    "section": "k = 10",
    "text": "k = 10\nHere we see our algorithm if we were to pick of k of 10. While we similar convergence times, it does less jumping around and has more of a constant decrease in loss.\n\ntorch.manual_seed(1234)\n\nloss_vec = perceptron_loop(X_multiple, y_multiple, k = 10, alpha = 1, plot = False)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")"
  },
  {
    "objectID": "posts/perceptron_blog.html#k-n",
    "href": "posts/perceptron_blog.html#k-n",
    "title": "Perceptron Blog Post",
    "section": "k = n",
    "text": "k = n\nWhat if k = n. Well in this scenerio, since we’re getting all of the points at once, alpha is the only thing changing our w. This means we’ll converge even on data that is not linearly seperable. Here we see that.\n\ntorch.manual_seed(123456)\n\nloss_vec = perceptron_loop(X_rand, y_rand, max_iter = 1000, k = X_rand.size()[0], alpha = 0.0001, plot = False)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\ntensor([0.5043, 0.8178, 0.4797])\ntensor([0.5043, 0.8178, 0.4797])\ntensor([0.5043, 0.8178, 0.4796])\ntensor([0.5043, 0.8178, 0.4796])\ntensor([0.5043, 0.8178, 0.4795])\ntensor([0.5043, 0.8178, 0.4795])\ntensor([0.5043, 0.8178, 0.4794])\ntensor([0.5043, 0.8178, 0.4794])\ntensor([0.5043, 0.8178, 0.4793])\ntensor([0.5043, 0.8178, 0.4793])\ntensor([0.5043, 0.8178, 0.4792])\ntensor([0.5043, 0.8178, 0.4792])\ntensor([0.5043, 0.8178, 0.4791])\ntensor([0.5043, 0.8178, 0.4791])\ntensor([0.5043, 0.8178, 0.4790])\ntensor([0.5043, 0.8178, 0.4790])\ntensor([0.5043, 0.8178, 0.4789])\ntensor([0.5043, 0.8178, 0.4789])\ntensor([0.5043, 0.8178, 0.4788])\ntensor([0.5043, 0.8178, 0.4788])\ntensor([0.5043, 0.8178, 0.4787])\ntensor([0.5043, 0.8178, 0.4787])\ntensor([0.5043, 0.8178, 0.4786])\ntensor([0.5043, 0.8178, 0.4786])\ntensor([0.5043, 0.8178, 0.4785])\ntensor([0.5043, 0.8178, 0.4785])\ntensor([0.5043, 0.8178, 0.4784])\ntensor([0.5043, 0.8178, 0.4784])\ntensor([0.5043, 0.8178, 0.4783])\ntensor([0.5043, 0.8178, 0.4783])\ntensor([0.5043, 0.8178, 0.4782])\ntensor([0.5042, 0.8178, 0.4782])\ntensor([0.5042, 0.8178, 0.4781])\ntensor([0.5042, 0.8178, 0.4781])\ntensor([0.5042, 0.8178, 0.4780])\ntensor([0.5042, 0.8178, 0.4780])\ntensor([0.5042, 0.8178, 0.4779])\ntensor([0.5042, 0.8178, 0.4779])\ntensor([0.5042, 0.8178, 0.4778])\ntensor([0.5042, 0.8178, 0.4778])\ntensor([0.5042, 0.8178, 0.4777])\ntensor([0.5042, 0.8178, 0.4777])\ntensor([0.5042, 0.8178, 0.4776])\ntensor([0.5042, 0.8178, 0.4776])\ntensor([0.5042, 0.8178, 0.4775])\ntensor([0.5042, 0.8178, 0.4775])\ntensor([0.5042, 0.8178, 0.4774])\ntensor([0.5042, 0.8178, 0.4774])\ntensor([0.5042, 0.8178, 0.4773])\ntensor([0.5042, 0.8178, 0.4773])\ntensor([0.5042, 0.8178, 0.4772])\ntensor([0.5042, 0.8178, 0.4772])\ntensor([0.5042, 0.8178, 0.4771])\ntensor([0.5042, 0.8178, 0.4771])\ntensor([0.5042, 0.8178, 0.4770])\ntensor([0.5042, 0.8178, 0.4770])\ntensor([0.5042, 0.8178, 0.4769])\ntensor([0.5042, 0.8178, 0.4769])\ntensor([0.5042, 0.8178, 0.4768])\ntensor([0.5042, 0.8178, 0.4768])\ntensor([0.5042, 0.8178, 0.4767])\ntensor([0.5042, 0.8178, 0.4767])\ntensor([0.5042, 0.8178, 0.4766])\ntensor([0.5042, 0.8178, 0.4766])\ntensor([0.5042, 0.8178, 0.4765])\ntensor([0.5042, 0.8178, 0.4765])\ntensor([0.5042, 0.8178, 0.4764])\ntensor([0.5042, 0.8178, 0.4764])\ntensor([0.5042, 0.8178, 0.4763])\ntensor([0.5042, 0.8178, 0.4763])\ntensor([0.5042, 0.8178, 0.4762])\ntensor([0.5042, 0.8178, 0.4762])\ntensor([0.5042, 0.8178, 0.4761])\ntensor([0.5042, 0.8178, 0.4761])\ntensor([0.5042, 0.8178, 0.4760])\ntensor([0.5042, 0.8178, 0.4760])\ntensor([0.5042, 0.8178, 0.4759])\ntensor([0.5042, 0.8178, 0.4759])\ntensor([0.5042, 0.8178, 0.4758])\ntensor([0.5042, 0.8179, 0.4758])\ntensor([0.5042, 0.8179, 0.4757])\ntensor([0.5042, 0.8179, 0.4757])\ntensor([0.5042, 0.8179, 0.4756])\ntensor([0.5042, 0.8179, 0.4756])\ntensor([0.5042, 0.8179, 0.4755])\ntensor([0.5042, 0.8179, 0.4755])\ntensor([0.5042, 0.8179, 0.4754])\ntensor([0.5042, 0.8179, 0.4754])\ntensor([0.5042, 0.8179, 0.4753])\ntensor([0.5042, 0.8179, 0.4753])\ntensor([0.5042, 0.8179, 0.4752])\ntensor([0.5042, 0.8179, 0.4752])\ntensor([0.5042, 0.8179, 0.4751])\ntensor([0.5042, 0.8179, 0.4751])\ntensor([0.5042, 0.8179, 0.4750])\ntensor([0.5042, 0.8179, 0.4750])\ntensor([0.5042, 0.8179, 0.4749])\ntensor([0.5042, 0.8179, 0.4749])\ntensor([0.5042, 0.8179, 0.4748])\ntensor([0.5042, 0.8179, 0.4748])\ntensor([0.5042, 0.8179, 0.4747])\ntensor([0.5042, 0.8179, 0.4747])\ntensor([0.5042, 0.8179, 0.4746])\ntensor([0.5042, 0.8179, 0.4746])\ntensor([0.5042, 0.8179, 0.4745])\ntensor([0.5042, 0.8179, 0.4745])\ntensor([0.5042, 0.8179, 0.4744])\ntensor([0.5042, 0.8179, 0.4744])\ntensor([0.5042, 0.8179, 0.4743])\ntensor([0.5042, 0.8179, 0.4743])\ntensor([0.5042, 0.8179, 0.4742])\ntensor([0.5042, 0.8179, 0.4742])\ntensor([0.5042, 0.8179, 0.4741])\ntensor([0.5042, 0.8179, 0.4741])\ntensor([0.5042, 0.8179, 0.4740])\ntensor([0.5042, 0.8179, 0.4740])\ntensor([0.5042, 0.8179, 0.4739])\ntensor([0.5042, 0.8179, 0.4739])\ntensor([0.5042, 0.8179, 0.4738])\ntensor([0.5042, 0.8179, 0.4738])\ntensor([0.5042, 0.8179, 0.4737])\ntensor([0.5042, 0.8179, 0.4737])\ntensor([0.5042, 0.8179, 0.4736])\ntensor([0.5042, 0.8179, 0.4736])\ntensor([0.5042, 0.8179, 0.4735])\ntensor([0.5042, 0.8179, 0.4735])\ntensor([0.5042, 0.8179, 0.4734])\ntensor([0.5042, 0.8179, 0.4734])\ntensor([0.5042, 0.8179, 0.4733])\ntensor([0.5042, 0.8179, 0.4733])\ntensor([0.5042, 0.8179, 0.4732])\ntensor([0.5042, 0.8179, 0.4732])\ntensor([0.5042, 0.8179, 0.4731])\ntensor([0.5042, 0.8179, 0.4731])\ntensor([0.5042, 0.8179, 0.4730])\ntensor([0.5042, 0.8179, 0.4730])\ntensor([0.5042, 0.8179, 0.4729])\ntensor([0.5042, 0.8179, 0.4729])\ntensor([0.5042, 0.8179, 0.4728])\ntensor([0.5042, 0.8179, 0.4728])\ntensor([0.5042, 0.8179, 0.4727])\ntensor([0.5042, 0.8179, 0.4727])\ntensor([0.5042, 0.8179, 0.4726])\ntensor([0.5042, 0.8179, 0.4726])\ntensor([0.5042, 0.8179, 0.4725])\ntensor([0.5042, 0.8179, 0.4725])\ntensor([0.5042, 0.8179, 0.4724])\ntensor([0.5042, 0.8179, 0.4724])\ntensor([0.5042, 0.8179, 0.4723])\ntensor([0.5042, 0.8179, 0.4723])\ntensor([0.5042, 0.8179, 0.4722])\ntensor([0.5041, 0.8179, 0.4722])\ntensor([0.5041, 0.8179, 0.4721])\ntensor([0.5041, 0.8179, 0.4721])\ntensor([0.5041, 0.8179, 0.4720])\ntensor([0.5041, 0.8179, 0.4720])\ntensor([0.5041, 0.8179, 0.4719])\ntensor([0.5041, 0.8179, 0.4719])\ntensor([0.5041, 0.8179, 0.4718])\ntensor([0.5041, 0.8179, 0.4718])\ntensor([0.5041, 0.8179, 0.4717])\ntensor([0.5041, 0.8179, 0.4717])\ntensor([0.5041, 0.8179, 0.4716])\ntensor([0.5041, 0.8179, 0.4716])\ntensor([0.5041, 0.8179, 0.4715])\ntensor([0.5041, 0.8179, 0.4715])\ntensor([0.5041, 0.8179, 0.4714])\ntensor([0.5041, 0.8179, 0.4714])\ntensor([0.5041, 0.8179, 0.4713])\ntensor([0.5041, 0.8179, 0.4713])\ntensor([0.5041, 0.8179, 0.4712])\ntensor([0.5041, 0.8179, 0.4712])\ntensor([0.5041, 0.8179, 0.4711])\ntensor([0.5041, 0.8179, 0.4711])\ntensor([0.5041, 0.8179, 0.4710])\ntensor([0.5041, 0.8179, 0.4710])\ntensor([0.5041, 0.8179, 0.4709])\ntensor([0.5041, 0.8179, 0.4709])\ntensor([0.5041, 0.8179, 0.4708])\ntensor([0.5041, 0.8179, 0.4708])\ntensor([0.5041, 0.8179, 0.4707])\ntensor([0.5041, 0.8179, 0.4707])\ntensor([0.5041, 0.8179, 0.4706])\ntensor([0.5041, 0.8179, 0.4706])\ntensor([0.5041, 0.8179, 0.4705])\ntensor([0.5041, 0.8179, 0.4705])\ntensor([0.5041, 0.8179, 0.4704])\ntensor([0.5041, 0.8179, 0.4704])\ntensor([0.5041, 0.8179, 0.4703])\ntensor([0.5041, 0.8179, 0.4703])\ntensor([0.5041, 0.8179, 0.4702])\ntensor([0.5041, 0.8179, 0.4702])\ntensor([0.5041, 0.8179, 0.4701])\ntensor([0.5041, 0.8179, 0.4701])\ntensor([0.5041, 0.8179, 0.4700])\ntensor([0.5041, 0.8179, 0.4700])\ntensor([0.5041, 0.8179, 0.4699])\ntensor([0.5041, 0.8179, 0.4699])\ntensor([0.5041, 0.8179, 0.4698])\ntensor([0.5041, 0.8179, 0.4698])\ntensor([0.5041, 0.8179, 0.4697])\ntensor([0.5041, 0.8179, 0.4697])\ntensor([0.5041, 0.8179, 0.4696])\ntensor([0.5041, 0.8179, 0.4696])\ntensor([0.5041, 0.8179, 0.4695])\ntensor([0.5041, 0.8179, 0.4695])\ntensor([0.5041, 0.8179, 0.4694])\ntensor([0.5041, 0.8179, 0.4694])\ntensor([0.5041, 0.8179, 0.4693])\ntensor([0.5041, 0.8179, 0.4693])\ntensor([0.5041, 0.8179, 0.4692])\ntensor([0.5041, 0.8179, 0.4692])\ntensor([0.5041, 0.8179, 0.4691])\ntensor([0.5041, 0.8179, 0.4691])\ntensor([0.5041, 0.8179, 0.4690])\ntensor([0.5041, 0.8179, 0.4690])\ntensor([0.5041, 0.8179, 0.4689])\ntensor([0.5041, 0.8179, 0.4689])\ntensor([0.5041, 0.8180, 0.4688])\ntensor([0.5041, 0.8180, 0.4688])\ntensor([0.5041, 0.8180, 0.4687])\ntensor([0.5041, 0.8180, 0.4687])\ntensor([0.5041, 0.8180, 0.4686])\ntensor([0.5041, 0.8180, 0.4686])\ntensor([0.5041, 0.8180, 0.4685])\ntensor([0.5041, 0.8180, 0.4685])\ntensor([0.5041, 0.8180, 0.4684])\ntensor([0.5041, 0.8180, 0.4684])\ntensor([0.5041, 0.8180, 0.4683])\ntensor([0.5041, 0.8180, 0.4683])\ntensor([0.5041, 0.8180, 0.4682])\ntensor([0.5041, 0.8180, 0.4682])\ntensor([0.5041, 0.8180, 0.4681])\ntensor([0.5041, 0.8180, 0.4681])\ntensor([0.5041, 0.8180, 0.4680])\ntensor([0.5041, 0.8180, 0.4680])\ntensor([0.5041, 0.8180, 0.4679])\ntensor([0.5041, 0.8180, 0.4679])\ntensor([0.5041, 0.8180, 0.4678])\ntensor([0.5041, 0.8180, 0.4678])\ntensor([0.5041, 0.8180, 0.4677])\ntensor([0.5041, 0.8180, 0.4677])\ntensor([0.5041, 0.8180, 0.4676])\ntensor([0.5041, 0.8180, 0.4676])\ntensor([0.5041, 0.8180, 0.4675])\ntensor([0.5041, 0.8180, 0.4675])\ntensor([0.5041, 0.8180, 0.4674])\ntensor([0.5041, 0.8180, 0.4674])\ntensor([0.5041, 0.8180, 0.4673])\ntensor([0.5041, 0.8180, 0.4673])\ntensor([0.5041, 0.8180, 0.4672])\ntensor([0.5041, 0.8180, 0.4672])\ntensor([0.5041, 0.8180, 0.4671])\ntensor([0.5041, 0.8180, 0.4671])\ntensor([0.5041, 0.8180, 0.4670])\ntensor([0.5041, 0.8180, 0.4670])\ntensor([0.5041, 0.8180, 0.4669])\ntensor([0.5041, 0.8180, 0.4669])\ntensor([0.5041, 0.8180, 0.4668])\ntensor([0.5041, 0.8180, 0.4668])\ntensor([0.5041, 0.8180, 0.4667])\ntensor([0.5041, 0.8180, 0.4667])\ntensor([0.5041, 0.8180, 0.4666])\ntensor([0.5041, 0.8180, 0.4666])\ntensor([0.5041, 0.8180, 0.4665])\ntensor([0.5041, 0.8180, 0.4665])\ntensor([0.5041, 0.8180, 0.4664])\ntensor([0.5041, 0.8180, 0.4664])\ntensor([0.5041, 0.8180, 0.4663])\ntensor([0.5041, 0.8180, 0.4663])\ntensor([0.5041, 0.8180, 0.4662])\ntensor([0.5040, 0.8180, 0.4662])\ntensor([0.5040, 0.8180, 0.4661])\ntensor([0.5040, 0.8180, 0.4661])\ntensor([0.5040, 0.8180, 0.4660])\ntensor([0.5040, 0.8180, 0.4660])\ntensor([0.5040, 0.8180, 0.4659])\ntensor([0.5040, 0.8180, 0.4659])\ntensor([0.5040, 0.8180, 0.4658])\ntensor([0.5040, 0.8180, 0.4658])\ntensor([0.5040, 0.8180, 0.4657])\ntensor([0.5040, 0.8180, 0.4657])\ntensor([0.5040, 0.8180, 0.4656])\ntensor([0.5040, 0.8180, 0.4656])\ntensor([0.5040, 0.8180, 0.4655])\ntensor([0.5040, 0.8180, 0.4655])\ntensor([0.5040, 0.8180, 0.4654])\ntensor([0.5040, 0.8180, 0.4654])\ntensor([0.5040, 0.8180, 0.4653])\ntensor([0.5040, 0.8180, 0.4653])\ntensor([0.5040, 0.8180, 0.4652])\ntensor([0.5040, 0.8180, 0.4652])\ntensor([0.5040, 0.8180, 0.4651])\ntensor([0.5040, 0.8180, 0.4651])\ntensor([0.5040, 0.8180, 0.4650])\ntensor([0.5040, 0.8180, 0.4650])\ntensor([0.5040, 0.8180, 0.4649])\ntensor([0.5040, 0.8180, 0.4649])\ntensor([0.5040, 0.8180, 0.4648])\ntensor([0.5040, 0.8180, 0.4648])\ntensor([0.5040, 0.8180, 0.4647])\ntensor([0.5040, 0.8180, 0.4647])\ntensor([0.5040, 0.8180, 0.4646])\ntensor([0.5040, 0.8180, 0.4646])\ntensor([0.5040, 0.8180, 0.4645])\ntensor([0.5040, 0.8180, 0.4645])\ntensor([0.5040, 0.8180, 0.4644])\ntensor([0.5040, 0.8180, 0.4644])\ntensor([0.5040, 0.8180, 0.4643])\ntensor([0.5040, 0.8180, 0.4643])\ntensor([0.5040, 0.8180, 0.4642])\ntensor([0.5040, 0.8180, 0.4642])\ntensor([0.5040, 0.8180, 0.4641])\ntensor([0.5040, 0.8180, 0.4641])\ntensor([0.5040, 0.8180, 0.4640])\ntensor([0.5040, 0.8180, 0.4640])\ntensor([0.5040, 0.8180, 0.4639])\ntensor([0.5040, 0.8180, 0.4639])\ntensor([0.5040, 0.8180, 0.4638])\ntensor([0.5040, 0.8180, 0.4638])\ntensor([0.5040, 0.8180, 0.4637])\ntensor([0.5040, 0.8180, 0.4637])\ntensor([0.5040, 0.8180, 0.4636])\ntensor([0.5040, 0.8180, 0.4636])\ntensor([0.5040, 0.8180, 0.4635])\ntensor([0.5040, 0.8180, 0.4635])\ntensor([0.5040, 0.8180, 0.4634])\ntensor([0.5040, 0.8180, 0.4634])\ntensor([0.5040, 0.8180, 0.4633])\ntensor([0.5040, 0.8180, 0.4633])\ntensor([0.5040, 0.8180, 0.4632])\ntensor([0.5040, 0.8180, 0.4632])\ntensor([0.5040, 0.8180, 0.4631])\ntensor([0.5040, 0.8180, 0.4631])\ntensor([0.5040, 0.8180, 0.4630])\ntensor([0.5040, 0.8180, 0.4630])\ntensor([0.5040, 0.8180, 0.4629])\ntensor([0.5040, 0.8180, 0.4629])\ntensor([0.5040, 0.8180, 0.4628])\ntensor([0.5040, 0.8180, 0.4628])\ntensor([0.5040, 0.8180, 0.4627])\ntensor([0.5040, 0.8180, 0.4627])\ntensor([0.5040, 0.8180, 0.4626])\ntensor([0.5040, 0.8180, 0.4626])\ntensor([0.5040, 0.8180, 0.4625])\ntensor([0.5040, 0.8180, 0.4625])\ntensor([0.5040, 0.8180, 0.4624])\ntensor([0.5040, 0.8180, 0.4624])\ntensor([0.5040, 0.8180, 0.4623])\ntensor([0.5040, 0.8180, 0.4623])\ntensor([0.5040, 0.8180, 0.4622])\ntensor([0.5040, 0.8180, 0.4622])\ntensor([0.5040, 0.8180, 0.4621])\ntensor([0.5040, 0.8180, 0.4621])\ntensor([0.5040, 0.8180, 0.4620])\ntensor([0.5040, 0.8180, 0.4620])\ntensor([0.5040, 0.8180, 0.4619])\ntensor([0.5040, 0.8180, 0.4619])\ntensor([0.5040, 0.8181, 0.4618])\ntensor([0.5040, 0.8181, 0.4618])\ntensor([0.5040, 0.8181, 0.4617])\ntensor([0.5040, 0.8181, 0.4617])\ntensor([0.5040, 0.8181, 0.4616])\ntensor([0.5040, 0.8181, 0.4616])\ntensor([0.5040, 0.8181, 0.4615])\ntensor([0.5040, 0.8181, 0.4615])\ntensor([0.5040, 0.8181, 0.4614])\ntensor([0.5040, 0.8181, 0.4614])\ntensor([0.5040, 0.8181, 0.4613])\ntensor([0.5040, 0.8181, 0.4613])\ntensor([0.5040, 0.8181, 0.4612])\ntensor([0.5040, 0.8181, 0.4612])\ntensor([0.5040, 0.8181, 0.4611])\ntensor([0.5040, 0.8181, 0.4611])\ntensor([0.5040, 0.8181, 0.4610])\ntensor([0.5040, 0.8181, 0.4610])\ntensor([0.5040, 0.8181, 0.4609])\ntensor([0.5040, 0.8181, 0.4609])\ntensor([0.5040, 0.8181, 0.4608])\ntensor([0.5040, 0.8181, 0.4608])\ntensor([0.5040, 0.8181, 0.4607])\ntensor([0.5040, 0.8181, 0.4607])\ntensor([0.5040, 0.8181, 0.4606])\ntensor([0.5040, 0.8181, 0.4606])\ntensor([0.5040, 0.8181, 0.4605])\ntensor([0.5040, 0.8181, 0.4605])\ntensor([0.5040, 0.8181, 0.4604])\ntensor([0.5040, 0.8181, 0.4604])\ntensor([0.5040, 0.8181, 0.4603])\ntensor([0.5040, 0.8181, 0.4603])\ntensor([0.5040, 0.8181, 0.4602])\ntensor([0.5039, 0.8181, 0.4602])\ntensor([0.5039, 0.8181, 0.4601])\ntensor([0.5039, 0.8181, 0.4601])\ntensor([0.5039, 0.8181, 0.4600])\ntensor([0.5039, 0.8181, 0.4600])\ntensor([0.5039, 0.8181, 0.4599])\ntensor([0.5039, 0.8181, 0.4599])\ntensor([0.5039, 0.8181, 0.4598])\ntensor([0.5039, 0.8181, 0.4598])\ntensor([0.5039, 0.8181, 0.4597])\ntensor([0.5039, 0.8181, 0.4597])\ntensor([0.5039, 0.8181, 0.4596])\ntensor([0.5039, 0.8181, 0.4596])\ntensor([0.5039, 0.8181, 0.4595])\ntensor([0.5039, 0.8181, 0.4595])\ntensor([0.5039, 0.8181, 0.4594])\ntensor([0.5039, 0.8181, 0.4594])\ntensor([0.5039, 0.8181, 0.4593])\ntensor([0.5039, 0.8181, 0.4593])\ntensor([0.5039, 0.8181, 0.4592])\ntensor([0.5039, 0.8181, 0.4592])\ntensor([0.5039, 0.8181, 0.4591])\ntensor([0.5039, 0.8181, 0.4591])\ntensor([0.5039, 0.8181, 0.4590])\ntensor([0.5039, 0.8181, 0.4590])\ntensor([0.5039, 0.8181, 0.4589])\ntensor([0.5039, 0.8181, 0.4589])\ntensor([0.5039, 0.8181, 0.4588])\ntensor([0.5039, 0.8181, 0.4588])\ntensor([0.5039, 0.8181, 0.4587])\ntensor([0.5039, 0.8181, 0.4587])\ntensor([0.5039, 0.8181, 0.4586])\ntensor([0.5039, 0.8181, 0.4586])\ntensor([0.5039, 0.8181, 0.4585])\ntensor([0.5039, 0.8181, 0.4585])\ntensor([0.5039, 0.8181, 0.4584])\ntensor([0.5039, 0.8181, 0.4584])\ntensor([0.5039, 0.8181, 0.4583])\ntensor([0.5039, 0.8181, 0.4583])\ntensor([0.5039, 0.8181, 0.4582])\ntensor([0.5039, 0.8181, 0.4582])\ntensor([0.5039, 0.8181, 0.4581])\ntensor([0.5039, 0.8181, 0.4581])\ntensor([0.5039, 0.8181, 0.4580])\ntensor([0.5039, 0.8181, 0.4580])\ntensor([0.5039, 0.8181, 0.4579])\ntensor([0.5039, 0.8181, 0.4579])\ntensor([0.5039, 0.8181, 0.4578])\ntensor([0.5039, 0.8181, 0.4578])\ntensor([0.5039, 0.8181, 0.4577])\ntensor([0.5039, 0.8181, 0.4577])\ntensor([0.5039, 0.8181, 0.4576])\ntensor([0.5039, 0.8181, 0.4576])\ntensor([0.5039, 0.8181, 0.4575])\ntensor([0.5039, 0.8181, 0.4575])\ntensor([0.5039, 0.8181, 0.4574])\ntensor([0.5039, 0.8181, 0.4574])\ntensor([0.5039, 0.8181, 0.4573])\ntensor([0.5039, 0.8181, 0.4573])\ntensor([0.5039, 0.8181, 0.4572])\ntensor([0.5039, 0.8181, 0.4572])\ntensor([0.5039, 0.8181, 0.4571])\ntensor([0.5039, 0.8181, 0.4571])\ntensor([0.5039, 0.8181, 0.4570])\ntensor([0.5039, 0.8181, 0.4570])\ntensor([0.5039, 0.8181, 0.4569])\ntensor([0.5039, 0.8181, 0.4569])\ntensor([0.5039, 0.8181, 0.4568])\ntensor([0.5039, 0.8181, 0.4568])\ntensor([0.5039, 0.8181, 0.4567])\ntensor([0.5039, 0.8181, 0.4567])\ntensor([0.5039, 0.8181, 0.4566])\ntensor([0.5039, 0.8181, 0.4566])\ntensor([0.5039, 0.8181, 0.4565])\ntensor([0.5039, 0.8181, 0.4565])\ntensor([0.5039, 0.8181, 0.4564])\ntensor([0.5039, 0.8181, 0.4564])\ntensor([0.5039, 0.8181, 0.4563])\ntensor([0.5039, 0.8181, 0.4563])\ntensor([0.5039, 0.8181, 0.4562])\ntensor([0.5039, 0.8181, 0.4562])\ntensor([0.5039, 0.8181, 0.4561])\ntensor([0.5039, 0.8181, 0.4561])\ntensor([0.5039, 0.8181, 0.4560])\ntensor([0.5039, 0.8181, 0.4560])\ntensor([0.5039, 0.8181, 0.4559])\ntensor([0.5039, 0.8181, 0.4559])\ntensor([0.5039, 0.8181, 0.4558])\ntensor([0.5039, 0.8181, 0.4558])\ntensor([0.5039, 0.8181, 0.4557])\ntensor([0.5039, 0.8181, 0.4557])\ntensor([0.5039, 0.8181, 0.4556])\ntensor([0.5039, 0.8181, 0.4556])\ntensor([0.5039, 0.8181, 0.4555])\ntensor([0.5039, 0.8181, 0.4555])\ntensor([0.5039, 0.8181, 0.4554])\ntensor([0.5039, 0.8181, 0.4554])\ntensor([0.5039, 0.8181, 0.4553])\ntensor([0.5039, 0.8181, 0.4553])\ntensor([0.5039, 0.8181, 0.4552])\ntensor([0.5039, 0.8181, 0.4552])\ntensor([0.5039, 0.8181, 0.4551])\ntensor([0.5039, 0.8181, 0.4551])\ntensor([0.5039, 0.8181, 0.4550])\ntensor([0.5039, 0.8181, 0.4550])\ntensor([0.5039, 0.8181, 0.4549])\ntensor([0.5039, 0.8181, 0.4549])\ntensor([0.5039, 0.8182, 0.4548])\ntensor([0.5039, 0.8182, 0.4548])\ntensor([0.5039, 0.8182, 0.4547])\ntensor([0.5039, 0.8182, 0.4547])\ntensor([0.5039, 0.8182, 0.4546])\ntensor([0.5039, 0.8182, 0.4546])\ntensor([0.5039, 0.8182, 0.4545])\ntensor([0.5039, 0.8182, 0.4545])\ntensor([0.5039, 0.8182, 0.4544])\ntensor([0.5039, 0.8182, 0.4544])\ntensor([0.5039, 0.8182, 0.4543])\ntensor([0.5039, 0.8182, 0.4543])\ntensor([0.5038, 0.8182, 0.4542])\ntensor([0.5038, 0.8182, 0.4542])\ntensor([0.5038, 0.8182, 0.4541])\ntensor([0.5038, 0.8182, 0.4541])\ntensor([0.5038, 0.8182, 0.4540])\ntensor([0.5038, 0.8182, 0.4540])\ntensor([0.5038, 0.8182, 0.4539])\ntensor([0.5038, 0.8182, 0.4539])\ntensor([0.5038, 0.8182, 0.4538])\ntensor([0.5038, 0.8182, 0.4538])\ntensor([0.5038, 0.8182, 0.4537])\ntensor([0.5038, 0.8182, 0.4537])\ntensor([0.5038, 0.8182, 0.4536])\ntensor([0.5038, 0.8182, 0.4536])\ntensor([0.5038, 0.8182, 0.4535])\ntensor([0.5038, 0.8182, 0.4535])\ntensor([0.5038, 0.8182, 0.4534])\ntensor([0.5038, 0.8182, 0.4534])\ntensor([0.5038, 0.8182, 0.4533])\ntensor([0.5038, 0.8182, 0.4533])\ntensor([0.5038, 0.8182, 0.4532])\ntensor([0.5038, 0.8182, 0.4532])\ntensor([0.5038, 0.8182, 0.4531])\ntensor([0.5038, 0.8182, 0.4531])\ntensor([0.5038, 0.8182, 0.4530])\ntensor([0.5038, 0.8182, 0.4530])\ntensor([0.5038, 0.8182, 0.4529])\ntensor([0.5038, 0.8182, 0.4529])\ntensor([0.5038, 0.8182, 0.4528])\ntensor([0.5038, 0.8182, 0.4528])\ntensor([0.5038, 0.8182, 0.4527])\ntensor([0.5038, 0.8182, 0.4527])\ntensor([0.5038, 0.8182, 0.4526])\ntensor([0.5038, 0.8182, 0.4526])\ntensor([0.5038, 0.8182, 0.4525])\ntensor([0.5038, 0.8182, 0.4525])\ntensor([0.5038, 0.8182, 0.4524])\ntensor([0.5038, 0.8182, 0.4524])\ntensor([0.5038, 0.8182, 0.4523])\ntensor([0.5038, 0.8182, 0.4523])\ntensor([0.5038, 0.8182, 0.4522])\ntensor([0.5038, 0.8182, 0.4522])\ntensor([0.5038, 0.8182, 0.4521])\ntensor([0.5038, 0.8182, 0.4521])\ntensor([0.5038, 0.8182, 0.4520])\ntensor([0.5038, 0.8182, 0.4520])\ntensor([0.5038, 0.8182, 0.4519])\ntensor([0.5038, 0.8182, 0.4519])\ntensor([0.5038, 0.8182, 0.4518])\ntensor([0.5038, 0.8182, 0.4518])\ntensor([0.5038, 0.8182, 0.4517])\ntensor([0.5038, 0.8182, 0.4517])\ntensor([0.5038, 0.8182, 0.4516])\ntensor([0.5038, 0.8182, 0.4516])\ntensor([0.5038, 0.8182, 0.4515])\ntensor([0.5038, 0.8182, 0.4515])\ntensor([0.5038, 0.8182, 0.4514])\ntensor([0.5038, 0.8182, 0.4514])\ntensor([0.5038, 0.8182, 0.4513])\ntensor([0.5038, 0.8182, 0.4513])\ntensor([0.5038, 0.8182, 0.4512])\ntensor([0.5038, 0.8182, 0.4512])\ntensor([0.5038, 0.8182, 0.4511])\ntensor([0.5038, 0.8182, 0.4511])\ntensor([0.5038, 0.8182, 0.4510])\ntensor([0.5038, 0.8182, 0.4510])\ntensor([0.5038, 0.8182, 0.4509])\ntensor([0.5038, 0.8182, 0.4509])\ntensor([0.5038, 0.8182, 0.4508])\ntensor([0.5038, 0.8182, 0.4508])\ntensor([0.5038, 0.8182, 0.4507])\ntensor([0.5038, 0.8182, 0.4507])\ntensor([0.5038, 0.8182, 0.4506])\ntensor([0.5038, 0.8182, 0.4506])\ntensor([0.5038, 0.8182, 0.4505])\ntensor([0.5038, 0.8182, 0.4505])\ntensor([0.5038, 0.8182, 0.4504])\ntensor([0.5038, 0.8182, 0.4504])\ntensor([0.5038, 0.8182, 0.4503])\ntensor([0.5038, 0.8182, 0.4503])\ntensor([0.5038, 0.8182, 0.4502])\ntensor([0.5038, 0.8182, 0.4502])\ntensor([0.5038, 0.8182, 0.4501])\ntensor([0.5038, 0.8182, 0.4501])\ntensor([0.5038, 0.8182, 0.4500])\ntensor([0.5038, 0.8182, 0.4500])\ntensor([0.5038, 0.8182, 0.4499])\ntensor([0.5038, 0.8182, 0.4499])\ntensor([0.5038, 0.8182, 0.4498])\ntensor([0.5038, 0.8182, 0.4498])\ntensor([0.5038, 0.8182, 0.4497])\ntensor([0.5038, 0.8182, 0.4497])\ntensor([0.5038, 0.8182, 0.4496])\ntensor([0.5038, 0.8182, 0.4496])\ntensor([0.5038, 0.8182, 0.4495])\ntensor([0.5038, 0.8182, 0.4495])\ntensor([0.5038, 0.8182, 0.4494])\ntensor([0.5038, 0.8182, 0.4494])\ntensor([0.5038, 0.8182, 0.4493])\ntensor([0.5038, 0.8182, 0.4493])\ntensor([0.5038, 0.8182, 0.4492])\ntensor([0.5038, 0.8182, 0.4492])\ntensor([0.5038, 0.8182, 0.4491])\ntensor([0.5038, 0.8182, 0.4491])\ntensor([0.5038, 0.8182, 0.4490])\ntensor([0.5038, 0.8182, 0.4490])\ntensor([0.5038, 0.8182, 0.4489])\ntensor([0.5038, 0.8182, 0.4489])\ntensor([0.5038, 0.8182, 0.4488])\ntensor([0.5038, 0.8182, 0.4488])\ntensor([0.5038, 0.8182, 0.4487])\ntensor([0.5038, 0.8182, 0.4487])\ntensor([0.5038, 0.8182, 0.4486])\ntensor([0.5038, 0.8182, 0.4486])\ntensor([0.5038, 0.8182, 0.4485])\ntensor([0.5038, 0.8182, 0.4485])\ntensor([0.5038, 0.8182, 0.4484])\ntensor([0.5038, 0.8182, 0.4484])\ntensor([0.5038, 0.8182, 0.4483])\ntensor([0.5038, 0.8182, 0.4483])\ntensor([0.5037, 0.8182, 0.4482])\ntensor([0.5037, 0.8182, 0.4482])\ntensor([0.5037, 0.8182, 0.4481])\ntensor([0.5037, 0.8182, 0.4481])\ntensor([0.5037, 0.8182, 0.4480])\ntensor([0.5037, 0.8182, 0.4480])\ntensor([0.5037, 0.8182, 0.4479])\ntensor([0.5037, 0.8182, 0.4479])\ntensor([0.5037, 0.8183, 0.4478])\ntensor([0.5037, 0.8183, 0.4478])\ntensor([0.5037, 0.8183, 0.4477])\ntensor([0.5037, 0.8183, 0.4477])\ntensor([0.5037, 0.8183, 0.4476])\ntensor([0.5037, 0.8183, 0.4476])\ntensor([0.5037, 0.8183, 0.4475])\ntensor([0.5037, 0.8183, 0.4475])\ntensor([0.5037, 0.8183, 0.4474])\ntensor([0.5037, 0.8183, 0.4474])\ntensor([0.5037, 0.8183, 0.4473])\ntensor([0.5037, 0.8183, 0.4473])\ntensor([0.5037, 0.8183, 0.4472])\ntensor([0.5037, 0.8183, 0.4472])\ntensor([0.5037, 0.8183, 0.4471])\ntensor([0.5037, 0.8183, 0.4471])\ntensor([0.5037, 0.8183, 0.4470])\ntensor([0.5037, 0.8183, 0.4470])\ntensor([0.5037, 0.8183, 0.4469])\ntensor([0.5037, 0.8183, 0.4469])\ntensor([0.5037, 0.8183, 0.4468])\ntensor([0.5037, 0.8183, 0.4468])\ntensor([0.5037, 0.8183, 0.4467])\ntensor([0.5037, 0.8183, 0.4467])\ntensor([0.5037, 0.8183, 0.4466])\ntensor([0.5037, 0.8183, 0.4466])\ntensor([0.5037, 0.8183, 0.4465])\ntensor([0.5037, 0.8183, 0.4465])\ntensor([0.5037, 0.8183, 0.4464])\ntensor([0.5037, 0.8183, 0.4464])\ntensor([0.5037, 0.8183, 0.4463])\ntensor([0.5037, 0.8183, 0.4463])\ntensor([0.5037, 0.8183, 0.4462])\ntensor([0.5037, 0.8183, 0.4462])\ntensor([0.5037, 0.8183, 0.4461])\ntensor([0.5037, 0.8183, 0.4461])\ntensor([0.5037, 0.8183, 0.4460])\ntensor([0.5037, 0.8183, 0.4460])\ntensor([0.5037, 0.8183, 0.4459])\ntensor([0.5037, 0.8183, 0.4459])\ntensor([0.5037, 0.8183, 0.4458])\ntensor([0.5037, 0.8183, 0.4458])\ntensor([0.5037, 0.8183, 0.4457])\ntensor([0.5037, 0.8183, 0.4457])\ntensor([0.5037, 0.8183, 0.4456])\ntensor([0.5037, 0.8183, 0.4456])\ntensor([0.5037, 0.8183, 0.4455])\ntensor([0.5037, 0.8183, 0.4455])\ntensor([0.5037, 0.8183, 0.4454])\ntensor([0.5037, 0.8183, 0.4454])\ntensor([0.5037, 0.8183, 0.4453])\ntensor([0.5037, 0.8183, 0.4453])\ntensor([0.5037, 0.8183, 0.4452])\ntensor([0.5037, 0.8183, 0.4452])\ntensor([0.5037, 0.8183, 0.4451])\ntensor([0.5037, 0.8183, 0.4451])\ntensor([0.5037, 0.8183, 0.4450])\ntensor([0.5037, 0.8183, 0.4450])\ntensor([0.5037, 0.8183, 0.4449])\ntensor([0.5037, 0.8183, 0.4449])\ntensor([0.5037, 0.8183, 0.4448])\ntensor([0.5037, 0.8183, 0.4448])\ntensor([0.5037, 0.8183, 0.4447])\ntensor([0.5037, 0.8183, 0.4447])\ntensor([0.5037, 0.8183, 0.4446])\ntensor([0.5037, 0.8183, 0.4446])\ntensor([0.5037, 0.8183, 0.4445])\ntensor([0.5037, 0.8183, 0.4445])\ntensor([0.5037, 0.8183, 0.4444])\ntensor([0.5037, 0.8183, 0.4444])\ntensor([0.5037, 0.8183, 0.4443])\ntensor([0.5037, 0.8183, 0.4443])\ntensor([0.5037, 0.8183, 0.4442])\ntensor([0.5037, 0.8183, 0.4442])\ntensor([0.5037, 0.8183, 0.4441])\ntensor([0.5037, 0.8183, 0.4441])\ntensor([0.5037, 0.8183, 0.4440])\ntensor([0.5037, 0.8183, 0.4440])\ntensor([0.5037, 0.8183, 0.4439])\ntensor([0.5037, 0.8183, 0.4439])\ntensor([0.5037, 0.8183, 0.4438])\ntensor([0.5037, 0.8183, 0.4438])\ntensor([0.5037, 0.8183, 0.4437])\ntensor([0.5037, 0.8183, 0.4437])\ntensor([0.5037, 0.8183, 0.4436])\ntensor([0.5037, 0.8183, 0.4436])\ntensor([0.5037, 0.8183, 0.4435])\ntensor([0.5037, 0.8183, 0.4435])\ntensor([0.5037, 0.8183, 0.4434])\ntensor([0.5037, 0.8183, 0.4434])\ntensor([0.5037, 0.8183, 0.4433])\ntensor([0.5037, 0.8183, 0.4433])\ntensor([0.5037, 0.8183, 0.4432])\ntensor([0.5037, 0.8183, 0.4432])\ntensor([0.5037, 0.8183, 0.4431])\ntensor([0.5037, 0.8183, 0.4431])\ntensor([0.5037, 0.8183, 0.4430])\ntensor([0.5037, 0.8183, 0.4430])\ntensor([0.5037, 0.8183, 0.4429])\ntensor([0.5037, 0.8183, 0.4429])\ntensor([0.5037, 0.8183, 0.4428])\ntensor([0.5037, 0.8183, 0.4428])\ntensor([0.5037, 0.8183, 0.4427])\ntensor([0.5037, 0.8183, 0.4427])\ntensor([0.5037, 0.8183, 0.4426])\ntensor([0.5037, 0.8183, 0.4426])\ntensor([0.5037, 0.8183, 0.4425])\ntensor([0.5037, 0.8183, 0.4425])\ntensor([0.5037, 0.8183, 0.4424])\ntensor([0.5036, 0.8183, 0.4424])\ntensor([0.5036, 0.8183, 0.4423])\ntensor([0.5036, 0.8183, 0.4423])\ntensor([0.5036, 0.8183, 0.4422])\ntensor([0.5036, 0.8183, 0.4422])\ntensor([0.5036, 0.8183, 0.4421])\ntensor([0.5036, 0.8183, 0.4421])\ntensor([0.5036, 0.8183, 0.4420])\ntensor([0.5036, 0.8183, 0.4420])\ntensor([0.5036, 0.8183, 0.4419])\ntensor([0.5036, 0.8183, 0.4419])\ntensor([0.5036, 0.8183, 0.4418])\ntensor([0.5036, 0.8183, 0.4418])\ntensor([0.5036, 0.8183, 0.4417])\ntensor([0.5036, 0.8183, 0.4417])\ntensor([0.5036, 0.8183, 0.4416])\ntensor([0.5036, 0.8183, 0.4416])\ntensor([0.5036, 0.8183, 0.4415])\ntensor([0.5036, 0.8183, 0.4415])\ntensor([0.5036, 0.8183, 0.4414])\ntensor([0.5036, 0.8183, 0.4414])\ntensor([0.5036, 0.8183, 0.4413])\ntensor([0.5036, 0.8183, 0.4413])\ntensor([0.5036, 0.8183, 0.4412])\ntensor([0.5036, 0.8183, 0.4412])\ntensor([0.5036, 0.8183, 0.4411])\ntensor([0.5036, 0.8183, 0.4411])\ntensor([0.5036, 0.8183, 0.4410])\ntensor([0.5036, 0.8183, 0.4410])\ntensor([0.5036, 0.8183, 0.4409])\ntensor([0.5036, 0.8183, 0.4409])\ntensor([0.5036, 0.8183, 0.4408])\ntensor([0.5036, 0.8183, 0.4408])\ntensor([0.5036, 0.8183, 0.4407])\ntensor([0.5036, 0.8183, 0.4407])\ntensor([0.5036, 0.8183, 0.4406])\ntensor([0.5036, 0.8183, 0.4406])\ntensor([0.5036, 0.8183, 0.4405])\ntensor([0.5036, 0.8183, 0.4405])\ntensor([0.5036, 0.8183, 0.4404])\ntensor([0.5036, 0.8183, 0.4404])\ntensor([0.5036, 0.8183, 0.4403])\ntensor([0.5036, 0.8183, 0.4403])\ntensor([0.5036, 0.8183, 0.4402])\ntensor([0.5036, 0.8184, 0.4402])\ntensor([0.5036, 0.8184, 0.4401])\ntensor([0.5036, 0.8184, 0.4401])\ntensor([0.5036, 0.8184, 0.4400])\ntensor([0.5036, 0.8184, 0.4400])\ntensor([0.5036, 0.8184, 0.4399])\ntensor([0.5036, 0.8184, 0.4399])\ntensor([0.5036, 0.8184, 0.4398])\ntensor([0.5036, 0.8184, 0.4398])\ntensor([0.5036, 0.8184, 0.4397])\ntensor([0.5036, 0.8184, 0.4397])\ntensor([0.5036, 0.8184, 0.4396])\ntensor([0.5036, 0.8184, 0.4396])\ntensor([0.5036, 0.8184, 0.4395])\ntensor([0.5036, 0.8184, 0.4395])\ntensor([0.5036, 0.8184, 0.4394])\ntensor([0.5036, 0.8184, 0.4394])\ntensor([0.5036, 0.8184, 0.4393])\ntensor([0.5036, 0.8184, 0.4393])\ntensor([0.5036, 0.8184, 0.4392])\ntensor([0.5036, 0.8184, 0.4392])\ntensor([0.5036, 0.8184, 0.4391])\ntensor([0.5036, 0.8184, 0.4391])\ntensor([0.5036, 0.8184, 0.4390])\ntensor([0.5036, 0.8184, 0.4390])\ntensor([0.5036, 0.8184, 0.4389])\ntensor([0.5036, 0.8184, 0.4389])\ntensor([0.5036, 0.8184, 0.4388])\ntensor([0.5036, 0.8184, 0.4388])\ntensor([0.5036, 0.8184, 0.4387])\ntensor([0.5036, 0.8184, 0.4387])\ntensor([0.5036, 0.8184, 0.4386])\ntensor([0.5036, 0.8184, 0.4386])\ntensor([0.5036, 0.8184, 0.4385])\ntensor([0.5036, 0.8184, 0.4385])\ntensor([0.5036, 0.8184, 0.4384])\ntensor([0.5036, 0.8184, 0.4384])\ntensor([0.5036, 0.8184, 0.4383])\ntensor([0.5036, 0.8184, 0.4383])\ntensor([0.5036, 0.8184, 0.4382])\ntensor([0.5036, 0.8184, 0.4382])\ntensor([0.5036, 0.8184, 0.4381])\ntensor([0.5036, 0.8184, 0.4381])\ntensor([0.5036, 0.8184, 0.4381])\ntensor([0.5036, 0.8184, 0.4380])\ntensor([0.5036, 0.8184, 0.4380])\ntensor([0.5036, 0.8184, 0.4379])\ntensor([0.5036, 0.8184, 0.4379])\ntensor([0.5036, 0.8184, 0.4378])\ntensor([0.5036, 0.8184, 0.4378])\ntensor([0.5036, 0.8184, 0.4377])\ntensor([0.5036, 0.8184, 0.4377])\ntensor([0.5036, 0.8184, 0.4376])\ntensor([0.5036, 0.8184, 0.4376])\ntensor([0.5036, 0.8184, 0.4375])\ntensor([0.5036, 0.8184, 0.4375])\ntensor([0.5036, 0.8184, 0.4374])\ntensor([0.5036, 0.8184, 0.4374])\ntensor([0.5036, 0.8184, 0.4373])\ntensor([0.5036, 0.8184, 0.4373])\ntensor([0.5036, 0.8184, 0.4372])\ntensor([0.5036, 0.8184, 0.4372])\ntensor([0.5036, 0.8184, 0.4371])\ntensor([0.5036, 0.8184, 0.4371])\ntensor([0.5036, 0.8184, 0.4370])\ntensor([0.5036, 0.8184, 0.4370])\ntensor([0.5036, 0.8184, 0.4369])\ntensor([0.5036, 0.8184, 0.4369])\ntensor([0.5035, 0.8184, 0.4368])\ntensor([0.5035, 0.8184, 0.4368])\ntensor([0.5035, 0.8184, 0.4367])\ntensor([0.5035, 0.8184, 0.4367])\ntensor([0.5035, 0.8184, 0.4366])\ntensor([0.5035, 0.8184, 0.4366])\ntensor([0.5035, 0.8184, 0.4365])\ntensor([0.5035, 0.8184, 0.4365])\ntensor([0.5035, 0.8184, 0.4364])\ntensor([0.5035, 0.8184, 0.4364])\ntensor([0.5035, 0.8184, 0.4363])\ntensor([0.5035, 0.8184, 0.4363])\ntensor([0.5035, 0.8184, 0.4362])\ntensor([0.5035, 0.8184, 0.4362])\ntensor([0.5035, 0.8184, 0.4361])\ntensor([0.5035, 0.8184, 0.4361])\ntensor([0.5035, 0.8184, 0.4360])\ntensor([0.5035, 0.8184, 0.4360])\ntensor([0.5035, 0.8184, 0.4359])\ntensor([0.5035, 0.8184, 0.4359])\ntensor([0.5035, 0.8184, 0.4358])\ntensor([0.5035, 0.8184, 0.4358])\ntensor([0.5035, 0.8184, 0.4357])\ntensor([0.5035, 0.8184, 0.4357])\ntensor([0.5035, 0.8184, 0.4356])\ntensor([0.5035, 0.8184, 0.4356])\ntensor([0.5035, 0.8184, 0.4355])\ntensor([0.5035, 0.8184, 0.4355])\ntensor([0.5035, 0.8184, 0.4354])\ntensor([0.5035, 0.8184, 0.4354])\ntensor([0.5035, 0.8184, 0.4353])\ntensor([0.5035, 0.8184, 0.4353])\ntensor([0.5035, 0.8184, 0.4352])\ntensor([0.5035, 0.8184, 0.4352])\ntensor([0.5035, 0.8184, 0.4351])\ntensor([0.5035, 0.8184, 0.4351])\ntensor([0.5035, 0.8184, 0.4350])\ntensor([0.5035, 0.8184, 0.4350])\ntensor([0.5035, 0.8184, 0.4349])\ntensor([0.5035, 0.8184, 0.4349])\ntensor([0.5035, 0.8184, 0.4348])\ntensor([0.5035, 0.8184, 0.4348])\ntensor([0.5035, 0.8184, 0.4347])\ntensor([0.5035, 0.8184, 0.4347])\ntensor([0.5035, 0.8184, 0.4346])\ntensor([0.5035, 0.8184, 0.4346])\ntensor([0.5035, 0.8184, 0.4345])\ntensor([0.5035, 0.8184, 0.4345])\ntensor([0.5035, 0.8184, 0.4344])\ntensor([0.5035, 0.8184, 0.4344])\ntensor([0.5035, 0.8184, 0.4343])\ntensor([0.5035, 0.8184, 0.4343])\ntensor([0.5035, 0.8184, 0.4342])\ntensor([0.5035, 0.8184, 0.4342])\ntensor([0.5035, 0.8184, 0.4341])\ntensor([0.5035, 0.8184, 0.4341])\ntensor([0.5035, 0.8184, 0.4340])\ntensor([0.5035, 0.8184, 0.4340])\ntensor([0.5035, 0.8184, 0.4340])\ntensor([0.5035, 0.8184, 0.4339])\ntensor([0.5035, 0.8184, 0.4339])\ntensor([0.5035, 0.8184, 0.4338])\ntensor([0.5035, 0.8184, 0.4338])\ntensor([0.5035, 0.8184, 0.4337])\ntensor([0.5035, 0.8184, 0.4337])\ntensor([0.5035, 0.8184, 0.4336])\ntensor([0.5035, 0.8184, 0.4336])\ntensor([0.5035, 0.8184, 0.4335])\ntensor([0.5035, 0.8184, 0.4335])\ntensor([0.5035, 0.8184, 0.4334])\ntensor([0.5035, 0.8184, 0.4334])\ntensor([0.5035, 0.8184, 0.4333])\ntensor([0.5035, 0.8184, 0.4333])\ntensor([0.5035, 0.8184, 0.4332])\ntensor([0.5035, 0.8184, 0.4332])\ntensor([0.5035, 0.8184, 0.4331])\ntensor([0.5035, 0.8184, 0.4331])\ntensor([0.5035, 0.8184, 0.4330])\ntensor([0.5035, 0.8184, 0.4330])\ntensor([0.5035, 0.8184, 0.4329])\ntensor([0.5035, 0.8184, 0.4329])\ntensor([0.5035, 0.8184, 0.4328])\ntensor([0.5035, 0.8184, 0.4328])\ntensor([0.5035, 0.8184, 0.4327])\ntensor([0.5035, 0.8184, 0.4327])\ntensor([0.5035, 0.8184, 0.4326])\ntensor([0.5035, 0.8184, 0.4326])\ntensor([0.5035, 0.8184, 0.4325])\ntensor([0.5035, 0.8184, 0.4325])\ntensor([0.5035, 0.8184, 0.4324])\ntensor([0.5035, 0.8184, 0.4324])\ntensor([0.5035, 0.8184, 0.4323])\ntensor([0.5035, 0.8184, 0.4323])\ntensor([0.5035, 0.8184, 0.4322])\ntensor([0.5035, 0.8184, 0.4322])\ntensor([0.5035, 0.8184, 0.4321])\ntensor([0.5035, 0.8184, 0.4321])\ntensor([0.5035, 0.8184, 0.4320])\ntensor([0.5035, 0.8184, 0.4320])\ntensor([0.5035, 0.8184, 0.4319])\ntensor([0.5035, 0.8184, 0.4319])\ntensor([0.5035, 0.8184, 0.4318])\ntensor([0.5035, 0.8184, 0.4318])\ntensor([0.5035, 0.8184, 0.4317])\ntensor([0.5034, 0.8184, 0.4317])\ntensor([0.5034, 0.8184, 0.4316])\ntensor([0.5034, 0.8184, 0.4316])\ntensor([0.5034, 0.8184, 0.4316])\ntensor([0.5034, 0.8184, 0.4315])\ntensor([0.5034, 0.8184, 0.4315])\ntensor([0.5034, 0.8184, 0.4314])\ntensor([0.5034, 0.8184, 0.4314])\ntensor([0.5034, 0.8184, 0.4313])\ntensor([0.5034, 0.8184, 0.4313])\ntensor([0.5034, 0.8184, 0.4312])\ntensor([0.5034, 0.8184, 0.4312])\ntensor([0.5034, 0.8184, 0.4311])\ntensor([0.5034, 0.8184, 0.4311])\ntensor([0.5034, 0.8184, 0.4310])\ntensor([0.5034, 0.8184, 0.4310])\ntensor([0.5034, 0.8184, 0.4309])\ntensor([0.5034, 0.8184, 0.4309])\ntensor([0.5034, 0.8184, 0.4308])\ntensor([0.5034, 0.8184, 0.4308])\ntensor([0.5034, 0.8184, 0.4307])\ntensor([0.5034, 0.8184, 0.4307])\ntensor([0.5034, 0.8184, 0.4306])\ntensor([0.5034, 0.8184, 0.4306])\ntensor([0.5034, 0.8184, 0.4305])\ntensor([0.5034, 0.8184, 0.4305])\ntensor([0.5034, 0.8184, 0.4304])\ntensor([0.5034, 0.8184, 0.4304])\ntensor([0.5034, 0.8184, 0.4303])\ntensor([0.5034, 0.8184, 0.4303])\ntensor([0.5034, 0.8184, 0.4302])\ntensor([0.5034, 0.8184, 0.4302])\ntensor([0.5034, 0.8184, 0.4301])\ntensor([0.5034, 0.8184, 0.4301])\ntensor([0.5034, 0.8184, 0.4300])\ntensor([0.5034, 0.8184, 0.4300])\ntensor([0.5034, 0.8184, 0.4299])"
  },
  {
    "objectID": "posts/perceptron_blog.html#runtime-considerations",
    "href": "posts/perceptron_blog.html#runtime-considerations",
    "title": "Perceptron Blog Post",
    "section": "Runtime Considerations",
    "text": "Runtime Considerations\nA single iterations of the perceptrong algorithm picks a point and calculates the loss of that point. To calculate the loss, we need to go through every point and see if it’s categorized correctly. This indicates that one iterations has a time complexity of O(n). Additionally if points have multiple features then this comparison increases to O(np) where p equals the number of features that we have. A mini-batch iterations takes slightly longer since we’re essentially doing multiple perceptron runs at one time. This increases the time complexity to O(knp) where k is the size of our batch. If our batch equals n, then the time complexity is O(pn^2)"
  },
  {
    "objectID": "posts/Women in Data Science.html",
    "href": "posts/Women in Data Science.html",
    "title": "Women in Data Science Blog Post",
    "section": "",
    "text": "Women’s in Data Science Blog Post\n\n\nAbstract\nThis blog posts discussed the importance of women in data science through the lens of the book Solving the Equation: The Variables for Women’s Success in Engineering and Computing written by Corbett and Hill and through four different talks by Amy Yuen, Jessica L’Roe, Dr. Sarah Brown, and Professor Biester. Each talk tackles a different problem or domain in data science and highlights the work being done by women in the field. My biggest takeways was that lots of women are doing incredibly interesting work in the data science domain despite being a minority in the field\n\n\nReading Questions\nFollowing are some reading questions for the book: Solving the Equation: The Variables for Women’s Success in Engineering and Computing written by Corbett and Hill that aim to bring some of the main themes of the reading.\nWhy is it a problem that women are underrepresented in computing, math, and engineering? For whom is it a problem?\nUnderrepresentation in computing, math, and engineering is a major problem because these industries have been major sources of high salaries and good working conditions. Leaving women out of these industries mean that they miss out on high income jobs and therefore wealth accumulation. The problem doesn’t only impact women but also also hurt men. One finding from India found that male leaders held less implicit bias when they had female leadership alongside them (Beaman et al., 2009). Inclusion doesn’t breed animosity but actually creates more equitable working conditions. Keeping women out of these industries also potentially misses out on valuable insights and innovations.\nHow is the representation and status of women in computing today different from the 1950s and 1960s? What are some of the forces that brought on this change?\nDuring World War 2, we actually saw a majority of women in the computing industry. This declined drastically after the war but in 1950s and 1960s the number of women in computing was similar to what it is today (around 26%). The percentaged reached a peak in the 1990s with around 35% of the computing workforce being women. Computing during the 1950s and 1960s was largely seen as an administrative extension and thereby women were encouraged to participate in large numbers. The decline after the 1990s is often attributed to the rise of personal computers which were seen as new toys for boys and the growing interest in the area. This early experience gave them an advantage as the computing market expanded. There has been, however, significant initiatives to raise the number of women in computing in recent years from major companies.\nWhich of the barriers and unequal challenges described in the section “Why So Few?” can be eroded by events that spotlight the achievement of women in STEM?\nHaving spotlight on women in the industry is an important step to reducing stigma and feelings of isolation while also giving role models for women in computer science. A third of women in private-sector technical jobs feel extremeley isolated at work and four out of ten female engineers reported a lack of role models. The book mentions how seeing other women in leadership roles can actually help women from the harmful effect of stereotyping effect (Van Loo & Rydell, 2014). These effects have a cascade effect as increase in female representation leads to more representation which further reduces feelings of isolation and increases representation.\nThese talks also begin the process of building social networks which has predominantly been dominated by men. The book highlights how research has identified that these male-dominated social networks exclude women (Faulkner, 2009a). Having women talk about their professional experiences and connect with students begins the process of opening up the network to women.\nFor this blog, I also attended a women in Data Science conference hosted by Middlebury. The conference included three lightning talks, one keynote speaker, and three alumni in the industry.\n\n\nFirst Lightning Talk Amy Yuen\nAmy Yuen’s talk discussed whether the United Nation Security Council is truly a Democratic Institution. On the onset, the voting rules seems to inherently favor the powerful since certain members are given veto powers. Why do other countries then spend significant resources and money on running for seats on the Security Council even if they have significantly less power? The talk analysis two different ways to look at democratic institutions: Institutional Rules which contains the voting inside the council and serving on the council; and Representation which looks at which issues are discussed and what the participation level of the non-permanent members are. The overall findings were that while the security council institutional rules aren’t very democratic, it is fairly representative and inclusive. From the talk, I learned about how one can use data for issues that are not necessarily data oriented. I wouldn’t at first think to use data analysis to come to a conclusion about the level of democracy of an institution since it feels more vague than other issues but now I do think it can be very useful to back up ones claims.\n\n\nSecond Lightning Talk Jessica L’Roe\nJessica L’Roe’s talk began with a note about how in college she only had one woman professor and that growing up in North Carolina, she was no stranger to having to constantly the fight gender expectations. The content of her talk was more a cursery overview of some of the projects that she has worked on with a more in-depth conservation about a specific project in Uganda. The first project looked at land registration in Brazil and her worked tried to encourage registrations so that people could more accurately be help culpable for deforestation. The second project looked at formalizing gold mining in Peru. Most of talk discussed a project dealing with landscape changes around Kibale National park in Uganda. They had an usual situation in which someone was planting lots of possibly invasive trees. Her work showed that many locals had given up their land to non-local people (sometimes to invest in other things like education) and this was driving the tree plantation. Jessica’s talk ended saying that women are no longer a rarity in these field and that anyone should pursue the things they are interested in.\n\n\nThird Lightning Talk Professor Laura Biester\nProf. Laura Biester’s talk was about computational linguistic models of mental health. This isn’t a new field either. Computers have been used since the 1980s to analyze language for mental health classifications. For example, one indicator is that first person pronouns are used more frequently by depressed people. However, there are many challenges to natural language processing. One of the main issues is access to high quality, complete, and objective data sets. Oftentimes if you rely one self-reporting, then the data doesn’t accurately encompass the general population. Prof. Biester has used Reddit posts to collect data which allows mass collection. However, to do this, you also need to collect posts from ‘control’ users. She also used a second university data set. This methodology proved effective as her model did well compared to other larger models. Overall, Prof. Biesters work showcased the importance of data collection. Data collection is almost as important as building the models themselves.\n\n\nKeynote Dr.Sarah Brown\nDr.Sarah Brown key note talk tackles some essential questions in machine learning and data science. Some of these key questions were: what is data science? How can we leverage domain knowledge to make better models? How can we make algorithms less biased? She touches on all of these ideas throughout her talk. She begins by discussing how data science is the intersections of Computer science, stats and domain knowledge. Domain knowledge, however, isn’t a concrete subject but can come from anywhere at any time. For example, for Dr.Brown she learned how to use context in Social Studies which she uses to understand data from data science. She uses an example from her work with PTSD patients to exemplify this lesson.\nDr.Brown then discusses fairness in models and her work in the area. One problem with models is that they are often made by computer scientists with a computer science viewpoint. Opening up the process to different fields can help reduce problems and bias because they can have insights that computer scientists can’t see. Dr.Brown also emphasizes that we should do fairness checks before even fitting the model. It is necessary to study the problem to see if a model can be used and if so, what are the possible biases that we could be receiving from the data. She discusses how experts in the field have various different opinions on whether fair algorithms are possible. The three main ones are: If you accept to lose accuracy, you can improve fairness, it isn’t possible and shouldn’t be tried, still progress to made on improving algorithms. Lastly, Dr.Brown discusses how because laws are slow to change to new technologies, we need a new methodology that encourages fairness.\nMy main takeaway from this talk was about the importance of a set workflow for data scientists and including fairness before model fitting. If that becomes a standard in the industry, we could hopefully reduce algorithmic bias before it gets implemented. I also found it interesting how she was able to construct other algorithms to test if an algorithm would be biased or not.\n\n\nDiscussion\nAs a man in computer science, I think it’s important for me to consider the inclusivity of the workplaces that I hope to join. It is partially priviledge that I don’t have to consider my own gender in the context of my career very often. This mostly comes from the unnerving truth that as a man, I will almost always be in the majority in this industry. Some of the facts in the book showed that the industry is way more male heavy than I believed and opened up my opinions of the industry. As someone who hopes to move up and eventually become a team leader, I need to be aware of how demographics impact peoples sense of belonging and inclusion. I also just found the talks interesting to listen to and contained some novel ideas about bias, data collection, and fairness that I hadn’t considered."
  },
  {
    "objectID": "posts/penguin_blog.html",
    "href": "posts/penguin_blog.html",
    "title": "Palmer Penguins Blog Post",
    "section": "",
    "text": "Palmer Penguins Blog Post\nAbstract In this blog posts, I delve into some of the factors that we can use to predict species in the palmer penguins dataset. I used SelectKBest and going through all combinations to select my columns that I’d use to try to predict species. Although both SelectKBest and combinations method got similar levels of accuracy, they selected slightly different columns. Finally, I visualize my model to showcase how future data predictions would look.\nImporting Palmer Penguins Data Set\n\nimport pandas as pd\nimport numpy as np\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nHere I am prepareing the data by dropping columns that don’t makes sense to train on or are constant for the data set. I also convert columns like Island into boolean columns using pandas getDummies.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = df.drop([\"Stage\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\nHere we can see what the new data looks like\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\nTable It’s always important to see the sample size of the different columns that we’re testing for. In this dataset, for example, we see that we have significantly more Adelie and Gentoo Penguins than Chinstrap penguins. In fact, we have twice as many Adelie penguins as Chinstrap ones. This isn’t ideal to train on because our model may choose to priorities features that classify Adelie penguins. For example, a naive classifier that classified only Adelie penguins correctly would have 43% accuracy while one that only classified Chinstrap ones would have 21% accuracy. If these were the only two options then the model would pick the 43% accuracy even tho it has a massive tilt.\n\ntrain.groupby(\"Species\").aggregate(\"count\")\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\nSpecies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\n120\n120\n120\n120\n120\n120\n120\n120\n119\n119\n119\n119\n114\n110\n110\n23\n\n\nChinstrap penguin (Pygoscelis antarctica)\n57\n57\n57\n57\n57\n57\n57\n57\n57\n57\n57\n57\n57\n56\n57\n0\n\n\nGentoo penguin (Pygoscelis papua)\n98\n98\n98\n98\n98\n98\n98\n98\n97\n97\n97\n97\n94\n96\n96\n0\n\n\n\n\n\n\n\nPlots This plot looks at the qualitative column “Island” and visualizes it to see if there would possibly be any trends that could be helpful. From the plot, we see that Chinstrap penguins are exclusively found on Dream, while Gentoo penguins are exclusively found on Biscoe Island.\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfig, ax = plt.subplots(1, figsize = (8, 3.5))\n\nplot = sns.countplot(train, x = \"Island\", hue = \"Species\")\n\n\n\n\n\n\n\n\nMy second graph visualizes Culment Length vs Flipper Length to see if there’s a correlation between the two and species. We see that Adelie penguins tend to have small culmen lengths and flippper lengths. Gentoo penguins, on the other hand, tend to have medium to large culmen lengths and long flipper lengths. Lastly, Chinstrap penguins tend to have long culmen lengths and medium to small flipper lengths.\n\nfig, ax = plt.subplots(1, 2, figsize = (8, 3.5))\n\np1 = sns.scatterplot(train, x = \"Culmen Length (mm)\", y = \"Flipper Length (mm)\", ax = ax[0], color = \"darkgrey\")\np2 = sns.scatterplot(train, x = \"Culmen Length (mm)\", y = \"Flipper Length (mm)\", hue = \"Species\", ax = ax[1])\n\n\n\n\n\n\n\n\nSelecting Features To select my features I try two different methods: SelectKBest and trying all possible combinations. Below we see my Select K Best implementation. I had to seperate out quantative and qualitative features so that SelectKBest didn’t choose 3 quantative features.\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif, chi2\n\ndef select_K_best(X, y, score_func, k):\n    selector = SelectKBest(score_func, k=k)\n    selector.fit(X, y)\n    return selector.get_feature_names_out()\n\n\nX_quant_selected = select_K_best(X_train[[\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]], y_train, f_classif, 2)\n\nX_qual_selected = select_K_best(X_train[[\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\", \"Clutch Completion_No\", \"Clutch Completion_Yes\", \"Sex_FEMALE\", \"Sex_MALE\"]], y_train, chi2, 1)\n\n\nX_quant_selected\n\narray(['Culmen Length (mm)', 'Flipper Length (mm)'], dtype=object)\n\n\n\nX_qual_selected = [col for col in X_train.columns if X_qual_selected[0][0:4] in col]\nX_qual_selected\n\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n\n\nHere we see all the rows selected in through SelectKBest\n\nselectK_cols = X_quant_selected.tolist() + X_qual_selected\nselectK_cols\n\n['Culmen Length (mm)',\n 'Flipper Length (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']\n\n\nI also implemented running through all combinations and calculating accuracy based on a random forrest algorithm. This method is significantly more time consuming than select k best but should return the most optimal columns.\n\nfrom itertools import combinations\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nclf = RandomForestClassifier(n_estimators=10, random_state=20)\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Island\", \"Clutch Completion\", \"Sex\"]\nall_quant_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]\n\nmean_score = 0\ncomb_cols = []\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    clf.fit(X_train[cols], y_train)\n    score = cross_val_score(clf, X_train[cols], y_train, cv=5)\n    if score.mean() &gt; mean_score:\n      mean_score = score.mean()\n      comb_cols = cols\ncomb_cols = comb_cols[3:5] + comb_cols[0:3]\ncomb_cols\n\n['Culmen Length (mm)',\n 'Culmen Depth (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']\n\n\nWhich Features to use To determine which algorithm to use, I test both possibility using cross val scores and using the random forrest classifier.\n\nselect_clf = RandomForestClassifier(n_estimators=40, random_state=40, max_depth=5)\nselect_clf.fit(X_train[selectK_cols], y_train)\nselect_score_clf = cross_val_score(select_clf, X_train[selectK_cols], y_train, cv=5)\nselect_score_clf.mean()\n\n0.9804675716440423\n\n\n\ncomb_clf = RandomForestClassifier(n_estimators=40, random_state=40, max_depth=5)\n\n\ncomb_clf.fit(X_train[comb_cols], y_train)\ncomb_score_clf = cross_val_score(comb_clf, X_train[comb_cols], y_train, cv=5)\ncomb_score_clf.mean()\n\n0.9804675716440423\n\n\nTesting My Data While the scores were similar, I decided to use the comb_clf. Now I’ll try to test it on the test data set.\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\ncomb_clf.score(X_test[comb_cols], y_test)\n\n1.0\n\n\nYay! As we can see we achieved a score of 100%.\nVisualizing Results This next block of code, given to us from Phil, helps show how our model classifies data. The one interesting thing to note is that Island Dream graph has several sharp blue ‘inlets’ that helps it categories certain Gentoo data points. This isn’t ideal and shows possibilites of overfitting.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\nplot_regions(comb_clf, X_train[comb_cols], y_train)\n\n\n\n\n\n\n\n\n\nplot_regions(comb_clf, X_test[comb_cols], y_test)\n\n\n\n\n\n\n\n\nSince the result has 100% accuracy, the confusion matrix won’t show much for the test set but it does show us that there aren’t an even amount of penguins types in the test set. This means that my algorithm could perform worse on under-represented test species.\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = comb_clf.predict(X_test[comb_cols])\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[31,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 26]])\n\n\nDiscussion I managed to achieve 100% accuracy for the test data! I found it interesting that the combination method and selectKBest selected different features, however there are a couple reasons I could think of why. First one is that selectKBest doesn’t take into account how features might interact with eachother. For example, two features may predict on part of the data really well while another feature may predict a different part slightly less well. The best algorithm would use both to train but selectKBest seems like it would only choose the two that help predict the same part of the data because they overall correlate better. I wonder how you can eliminate this weakness on datasets where you can’t go through every combination. Even with the combination features, from the visualizations we see that the model created isn’t perfect. The graph shows a couple slim lines that perfectly allow some data points to get correctly labeled which shows some weakness in the model. With a larger test dataset, I’m sure this overfitting wouldn’t hold for all data points in that area. In the future, I would love to try different models to see if and how they might come up with varying degrees of accuracy."
  },
  {
    "objectID": "posts/Replication Study.html",
    "href": "posts/Replication Study.html",
    "title": "Replication Study",
    "section": "",
    "text": "In this blog post, I followed along with the study by Obermeyer, Ziad, Brian Powers, Christine Vogeli, and Sendhil Mullainathan (2019) called “Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.” This blog posts steps through their methodology to understand how they got to the conclusions that they did. I found that there existed a black and white patient divide in the correlation between the mean number of chronic illness and risk percentile. However, I didn’t find that figure 3 shows a significant different as between black and white patients as people with over 5 chronic illnesses blurs teh picture. I also found that there existed a disportionate cost of black patients compared to white patients.\n\nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\ndf[\"risk_percentile\"] = (df[\"risk_score_t\"].rank(pct=True) * 100).round()\n\n\n\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nchart = df.groupby([\"risk_percentile\", \"race\"]).aggregate({\"gagne_sum_t\" : \"mean\"}).reset_index()\n\nsns.scatterplot(data=chart, x=\"gagne_sum_t\", y=\"risk_percentile\", hue=\"race\")\nplt.xlabel(\"Mean Number of Chronic Illnesses\")\nplt.ylabel(\"Risk Percentile\")\nplt.grid(True)\n\n\n\n\n\n\n\n\n\n\n\nThe chart shows the White patients on average have to have less chronic illnesses to have higher risk. This means that white patients are more likely to be referred to treatment (high risk treatment) than black patients. For example, a white patient with a risk percentile of 60 needs on average around 1.1 chronic illnesses while a black patient would need to have around 1.8-1.9 chronic illness to be in that same risk percentile.\n\n\n\n\nchart2 = df.groupby([\"risk_percentile\", \"race\"]).aggregate({\"cost_t\" : \"mean\"}).reset_index()\nfig, ax = plt.subplots(1, 2, figsize = (8, 3.5))\n\nsns.scatterplot(data=chart2, x=\"risk_percentile\", y=\"cost_t\", hue=\"race\", ax=ax[0])\nax[0].set(xlabel =\"Percentile Risk Score\", ylabel = \"Medical Cost\", yscale=\"log\")\n\nchart3 = df.groupby([\"race\", \"gagne_sum_t\"]).aggregate({\"cost_t\" : \"mean\"}).reset_index()\n\nsns.scatterplot(data=chart3, x=\"gagne_sum_t\", y=\"cost_t\", hue=\"race\", ax=ax[1])\nax[1].set(xlabel =\"Number of Chronic Of Illnesses\", ylabel = \"Medical Cost\", yscale=\"log\")\n\n[Text(0.5, 0, 'Number of Chronic Of Illnesses'),\n Text(0, 0.5, 'Medical Cost'),\n None]\n\n\n\n\n\n\n\n\n\n\n\nThe paper argues that there is little difference in cost based on percentile risk shown in Figure 1 but that black patients tend to have lower costs for the number of chronic illnesses they have. I’m not sure the tables I created totally supports that hypothesis as both seem to have small differences between them. For example, between 7 and 14 chronic illnesses, it looks like black patients actually cost more than white patients. This could be because there’s not very many patients with over 5 chronic illnesses.\n\n\n\n\nYou might have noticed that there isn’t much data about patients with 5 or less chronic illnesses. Therefore, we are going to limit the dataset to only patients with 5 or less chronic illnesses to prevent outliers.\n\nfiveOrLess = df[df[\"gagne_sum_t\"] &lt; 5]\n\npercentage = len(fiveOrLess)/len(df) * 100\nprint(\"Percentage of patients with 5 or less chronic illnesses: \", round(percentage, 2), \"%\")\n\nPercentage of patients with 5 or less chronic illnesses:  93.0 %\n\n\nHere we calculate the log cost. This is important because our target variable varies widely across several orders of magnitude.\n\nfiveOrLess = fiveOrLess[fiveOrLess[\"cost_t\"] &gt; 0]\nfiveOrLess[\"log_cost\"] = fiveOrLess[\"cost_t\"].transform(\"log\")\n\nIn this step, we create a dummy column that has 0 meaning that the parient is white and 1 meaning that the patient is black. I also found that only 10% of the patients in this study were black. This is however not terribly lower than the U.S population average of 13%.\n\nfiveOrLess[\"race_dummy\"] = 1 * (fiveOrLess[\"race\"] == \"black\")\nfiveOrLess[\"race_dummy\"].mean()\n\n0.10478072089871121\n\n\n\nX_train = fiveOrLess[[\"race_dummy\", \"gagne_sum_t\"]]\ny_train = fiveOrLess[\"log_cost\"]\n\n\n\n\nSince we are trying to fit a non-linear function with a linear regression, we can add polynomial features to improve our model. For example, in the following code block, I add polynomials of gagne_sum_t up to 8 degrees and print out the cross valuation score. I then pick the degree with the best score to use for my model.\n\ndef add_polynomial_features(X, degree):\n  X_ = X.copy()\n  for j in range(1, degree):\n    X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n  return X_\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\nfor degree in range(1, 6):\n    LR = LinearRegression()\n    X_polyTrain = add_polynomial_features(X_train, degree)\n    LR.fit(X_polyTrain, y_train)\n    cv_score_LR = cross_val_score(LR, X_polyTrain, y_train, cv=5)\n    print(f\"Degree {degree}: {cv_score_LR.mean()}\")\n\nDegree 1: 0.0707003471161072\nDegree 2: 0.07069112920880076\nDegree 3: 0.07180211781434358\nDegree 4: 0.07245274257563275\nDegree 5: 0.07313225738549074\n\n\n\n\n\nAs we can see, degree 5 has the best score so we will select that to train our model which I do in the next step. It also makes sense with the fact that at over 5 conditions, our data becomes more sparse.\n\nFinalLR = LinearRegression()\nX_trainFinal = add_polynomial_features(X_train, 5)\nFinalLR.fit(X_trainFinal, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\nprint(X_trainFinal.columns)\nprint(FinalLR.coef_)\n\nIndex(['race_dummy', 'gagne_sum_t', 'poly_1', 'poly_2', 'poly_3', 'poly_4'], dtype='object')\n[-2.87073428e-01 -1.02948142e+11  1.02948142e+11 -7.32982800e-01\n  2.72133230e-01 -3.23777558e-02]\n\n\n\n\n\nWe can now calculate the cost incurred by black patients. We calculate that in the next code block by finding the coefficient that corresponds with race.\n\nimport numpy as np\nnp.exp(LR.coef_[0])\n\n0.7504566226125335\n\n\nHere we see that the percentage cost of black patients is unsually high at around 76.6%.\n\n\nAs mentioned in the abstract, this paper found that there existed a black and white patient divide in the correlation between the mean number of chronic illness and risk percentile. It found that there existed a disportionate cost of black patients compared to white patients with 76.6%. Essentially that when black patients have similar levels of chronic illness at white patients, they are still recieving lower scores than their counterparts. This means that less black patients are not recieving the care that they need since they overall have lower scores. These results are in line with those that Obermeyer et al. (2019) found in their paper. This exercises showcases how past historical data, like how black patients tend to recieve less care, can creep into algorithmic decision making.\nOf the three types of algorithmic bias guidelines: error rate parity, acceptance rate parity, and sufficiency, the study by Obermeyer et al. (2019) most clearly looks at error rate parity. This is because when we examine risk percentile scores to medical costs, we don’t see much of a difference between races. However, when we examine who gets what risk percentile scores, we see that white patients are often possibly higher scores than they are supposed to while black patients are given lower scores. Obermeyer points out that the algorithm falsely concludes that “black patients are healthier than equally sick white patients”."
  },
  {
    "objectID": "posts/Replication Study.html#figure-1",
    "href": "posts/Replication Study.html#figure-1",
    "title": "Replication Study",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport seaborn as sns\n\nchart = df.groupby([\"risk_percentile\", \"race\"]).aggregate({\"gagne_sum_t\" : \"mean\"}).reset_index()\n\nsns.scatterplot(data=chart, x=\"gagne_sum_t\", y=\"risk_percentile\", hue=\"race\")\nplt.xlabel(\"Mean Number of Chronic Illnesses\")\nplt.ylabel(\"Risk Percentile\")\nplt.grid(True)"
  },
  {
    "objectID": "posts/Replication Study.html#explaining-fig-1",
    "href": "posts/Replication Study.html#explaining-fig-1",
    "title": "Replication Study",
    "section": "",
    "text": "The chart shows the White patients on average have to have less chronic illnesses to have higher risk. This means that white patients are more likely to be referred to treatment (high risk treatment) than black patients. For example, a white patient with a risk percentile of 60 needs on average around 1.1 chronic illnesses while a black patient would need to have around 1.8-1.9 chronic illness to be in that same risk percentile."
  },
  {
    "objectID": "posts/Replication Study.html#figure-3",
    "href": "posts/Replication Study.html#figure-3",
    "title": "Replication Study",
    "section": "",
    "text": "chart2 = df.groupby([\"risk_percentile\", \"race\"]).aggregate({\"cost_t\" : \"mean\"}).reset_index()\nfig, ax = plt.subplots(1, 2, figsize = (8, 3.5))\n\nsns.scatterplot(data=chart2, x=\"risk_percentile\", y=\"cost_t\", hue=\"race\", ax=ax[0])\nax[0].set(xlabel =\"Percentile Risk Score\", ylabel = \"Medical Cost\", yscale=\"log\")\n\nchart3 = df.groupby([\"race\", \"gagne_sum_t\"]).aggregate({\"cost_t\" : \"mean\"}).reset_index()\n\nsns.scatterplot(data=chart3, x=\"gagne_sum_t\", y=\"cost_t\", hue=\"race\", ax=ax[1])\nax[1].set(xlabel =\"Number of Chronic Of Illnesses\", ylabel = \"Medical Cost\", yscale=\"log\")\n\n[Text(0.5, 0, 'Number of Chronic Of Illnesses'),\n Text(0, 0.5, 'Medical Cost'),\n None]\n\n\n\n\n\n\n\n\n\n\n\nThe paper argues that there is little difference in cost based on percentile risk shown in Figure 1 but that black patients tend to have lower costs for the number of chronic illnesses they have. I’m not sure the tables I created totally supports that hypothesis as both seem to have small differences between them. For example, between 7 and 14 chronic illnesses, it looks like black patients actually cost more than white patients. This could be because there’s not very many patients with over 5 chronic illnesses."
  },
  {
    "objectID": "posts/Replication Study.html#splitting-data",
    "href": "posts/Replication Study.html#splitting-data",
    "title": "Replication Study",
    "section": "",
    "text": "You might have noticed that there isn’t much data about patients with 5 or less chronic illnesses. Therefore, we are going to limit the dataset to only patients with 5 or less chronic illnesses to prevent outliers.\n\nfiveOrLess = df[df[\"gagne_sum_t\"] &lt; 5]\n\npercentage = len(fiveOrLess)/len(df) * 100\nprint(\"Percentage of patients with 5 or less chronic illnesses: \", round(percentage, 2), \"%\")\n\nPercentage of patients with 5 or less chronic illnesses:  93.0 %\n\n\nHere we calculate the log cost. This is important because our target variable varies widely across several orders of magnitude.\n\nfiveOrLess = fiveOrLess[fiveOrLess[\"cost_t\"] &gt; 0]\nfiveOrLess[\"log_cost\"] = fiveOrLess[\"cost_t\"].transform(\"log\")\n\nIn this step, we create a dummy column that has 0 meaning that the parient is white and 1 meaning that the patient is black. I also found that only 10% of the patients in this study were black. This is however not terribly lower than the U.S population average of 13%.\n\nfiveOrLess[\"race_dummy\"] = 1 * (fiveOrLess[\"race\"] == \"black\")\nfiveOrLess[\"race_dummy\"].mean()\n\n0.10478072089871121\n\n\n\nX_train = fiveOrLess[[\"race_dummy\", \"gagne_sum_t\"]]\ny_train = fiveOrLess[\"log_cost\"]"
  },
  {
    "objectID": "posts/Replication Study.html#polynomial-features",
    "href": "posts/Replication Study.html#polynomial-features",
    "title": "Replication Study",
    "section": "",
    "text": "Since we are trying to fit a non-linear function with a linear regression, we can add polynomial features to improve our model. For example, in the following code block, I add polynomials of gagne_sum_t up to 8 degrees and print out the cross valuation score. I then pick the degree with the best score to use for my model.\n\ndef add_polynomial_features(X, degree):\n  X_ = X.copy()\n  for j in range(1, degree):\n    X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n  return X_\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\nfor degree in range(1, 6):\n    LR = LinearRegression()\n    X_polyTrain = add_polynomial_features(X_train, degree)\n    LR.fit(X_polyTrain, y_train)\n    cv_score_LR = cross_val_score(LR, X_polyTrain, y_train, cv=5)\n    print(f\"Degree {degree}: {cv_score_LR.mean()}\")\n\nDegree 1: 0.0707003471161072\nDegree 2: 0.07069112920880076\nDegree 3: 0.07180211781434358\nDegree 4: 0.07245274257563275\nDegree 5: 0.07313225738549074"
  },
  {
    "objectID": "posts/Replication Study.html#selecting-degree",
    "href": "posts/Replication Study.html#selecting-degree",
    "title": "Replication Study",
    "section": "",
    "text": "As we can see, degree 5 has the best score so we will select that to train our model which I do in the next step. It also makes sense with the fact that at over 5 conditions, our data becomes more sparse.\n\nFinalLR = LinearRegression()\nX_trainFinal = add_polynomial_features(X_train, 5)\nFinalLR.fit(X_trainFinal, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\nprint(X_trainFinal.columns)\nprint(FinalLR.coef_)\n\nIndex(['race_dummy', 'gagne_sum_t', 'poly_1', 'poly_2', 'poly_3', 'poly_4'], dtype='object')\n[-2.87073428e-01 -1.02948142e+11  1.02948142e+11 -7.32982800e-01\n  2.72133230e-01 -3.23777558e-02]"
  },
  {
    "objectID": "posts/Replication Study.html#getting-cost",
    "href": "posts/Replication Study.html#getting-cost",
    "title": "Replication Study",
    "section": "",
    "text": "We can now calculate the cost incurred by black patients. We calculate that in the next code block by finding the coefficient that corresponds with race.\n\nimport numpy as np\nnp.exp(LR.coef_[0])\n\n0.7504566226125335\n\n\nHere we see that the percentage cost of black patients is unsually high at around 76.6%.\n\n\nAs mentioned in the abstract, this paper found that there existed a black and white patient divide in the correlation between the mean number of chronic illness and risk percentile. It found that there existed a disportionate cost of black patients compared to white patients with 76.6%. Essentially that when black patients have similar levels of chronic illness at white patients, they are still recieving lower scores than their counterparts. This means that less black patients are not recieving the care that they need since they overall have lower scores. These results are in line with those that Obermeyer et al. (2019) found in their paper. This exercises showcases how past historical data, like how black patients tend to recieve less care, can creep into algorithmic decision making.\nOf the three types of algorithmic bias guidelines: error rate parity, acceptance rate parity, and sufficiency, the study by Obermeyer et al. (2019) most clearly looks at error rate parity. This is because when we examine risk percentile scores to medical costs, we don’t see much of a difference between races. However, when we examine who gets what risk percentile scores, we see that white patients are often possibly higher scores than they are supposed to while black patients are given lower scores. Obermeyer points out that the algorithm falsely concludes that “black patients are healthier than equally sick white patients”."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Perceptron Blog Post\n\n\n\n\n\nBlog Post for the Fourth Assignment in CS0451\n\n\n\n\n\nApr 2, 2024\n\n\nOtis Milliken\n\n\n\n\n\n\n\n\n\n\n\n\nWomen in Data Science Blog Post\n\n\n\n\n\nBlog Post for CS0451\n\n\n\n\n\nMar 4, 2024\n\n\nOtis Milliken\n\n\n\n\n\n\n\n\n\n\n\n\nReplication Study\n\n\n\n\n\nBlog Post for CS0451\n\n\n\n\n\nMar 3, 2024\n\n\nOtis Milliken\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins Blog Post\n\n\n\n\n\nBlog Post for the First Assignment in CS0451\n\n\n\n\n\nFeb 20, 2024\n\n\nOtis Milliken\n\n\n\n\n\n\nNo matching items"
  }
]